<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <title>Improving Communication Access - PARADISEC Workflows</title> <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>Improving Communication Access | PARADISEC Workflows</title> <meta name="generator" content="Jekyll v3.9.0" /> <meta property="og:title" content="Improving Communication Access" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="PARADISEC technical workflows and archiving guides" /> <meta property="og:description" content="PARADISEC technical workflows and archiving guides" /> <link rel="canonical" href="http://localhost:4000/10_improving_communication_access.html" /> <meta property="og:url" content="http://localhost:4000/10_improving_communication_access.html" /> <meta property="og:site_name" content="PARADISEC Workflows" /> <script type="application/ld+json"> {"@type":"WebPage","description":"PARADISEC technical workflows and archiving guides","headline":"Improving Communication Access","url":"http://localhost:4000/10_improving_communication_access.html","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> PARADISEC Workflows </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Overview</a></li><li class="nav-list-item"><a href="http://localhost:4000/02_getting-started.html" class="nav-list-link">Getting Started with PARADISEC</a></li><li class="nav-list-item"><a href="http://localhost:4000/03_data_management.html" class="nav-list-link">Metadata & Data Management</a></li><li class="nav-list-item"><a href="http://localhost:4000/04_suggested_specifications.html" class="nav-list-link">Suggested specifications for digital capture</a></li><li class="nav-list-item"><a href="http://localhost:4000/05_digitising_manuscripts.html" class="nav-list-link">Digitising Manuscripts & Field Notebooks</a></li><li class="nav-list-item"><a href="http://localhost:4000/06_audio_digitising.html" class="nav-list-link">Audio Digitising</a></li><li class="nav-list-item"><a href="http://localhost:4000/07_audio_processing.html" class="nav-list-link">Audio Processing</a></li><li class="nav-list-item"><a href="http://localhost:4000/08_video_processing_MP4.html" class="nav-list-link">Video Processing - MP4 (H.264)</a></li><li class="nav-list-item"><a href="http://localhost:4000/09_video_processing_MXF.html" class="nav-list-link">Video Processing - MXF</a></li><li class="nav-list-item active"><a href="http://localhost:4000/10_improving_communication_access.html" class="nav-list-link active">Improving Communication Access</a></li><li class="nav-list-item"><a href="http://localhost:4000/11_PDSC_ingestion_workflow.html" class="nav-list-link">PARADISEC Internal Ingestion Model</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search PARADISEC Workflows" aria-label="Search PARADISEC Workflows" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="//github.com/paradisec-archive/PARADISEC_workflows" class="site-button" target="_blank" rel="noopener noreferrer" > PARADISEC Workflows on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <div id="main-content" class="main-content" role="main"> <details closed=""> <summary class="text-delta"> Table of contents </summary> <ol id="markdown-toc"> <li><a href="#improving-communication-access-for-deaf-and-hard-of-hearing-people" id="markdown-toc-improving-communication-access-for-deaf-and-hard-of-hearing-people">Improving communication access for deaf and hard of hearing people</a> <ol> <li><a href="#captioning-options-to-improve-accessibility-of-your-audio-visual-content" id="markdown-toc-captioning-options-to-improve-accessibility-of-your-audio-visual-content">Captioning options to improve accessibility of your audio-visual content</a> <ol> <li><a href="#some-terms-used" id="markdown-toc-some-terms-used">Some terms used</a></li> <li><a href="#what-type-of-access-could-be-offered-and-when" id="markdown-toc-what-type-of-access-could-be-offered-and-when">What type of access could be offered and when?</a></li> <li><a href="#how-to-caption-pre-recorded-content" id="markdown-toc-how-to-caption-pre-recorded-content">How to caption pre-recorded content</a> <ol> <li><a href="#creating-captions-using-youtube" id="markdown-toc-creating-captions-using-youtube">Creating captions using YouTube</a></li> <li><a href="#options-for-live-captioning-of-online-event" id="markdown-toc-options-for-live-captioning-of-online-event">Options for live captioning of online event</a> <ol> <li><a href="#captions-by-ai--artificial-intelligence" id="markdown-toc-captions-by-ai--artificial-intelligence">Captions by AI -Artificial Intelligence</a></li> <li><a href="#live-human-captioning-during-online-meeting" id="markdown-toc-live-human-captioning-during-online-meeting">Live human captioning during online meeting</a></li> </ol> </li> </ol> </li> </ol> </li> <li><a href="#providing-interpreters-who-can-work-between-signed-and-spoken-languages" id="markdown-toc-providing-interpreters-who-can-work-between-signed-and-spoken-languages">Providing interpreters who can work between signed and spoken languages</a></li> </ol> </li> </ol> </details> <style> H5{color:White !important;} </style> <style> H6{color:White !important;} </style> <h2 id="improving-communication-access-for-deaf-and-hard-of-hearing-people"> <a href="#improving-communication-access-for-deaf-and-hard-of-hearing-people" class="anchor-heading" aria-labelledby="improving-communication-access-for-deaf-and-hard-of-hearing-people"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Improving communication access for deaf and hard of hearing people </h2> <p><br /></p> <p>Developed by <a href="mailto:julia.miller@anu.edu.au">Julia Miller</a> &amp; <a href="mailto:g.hodge@ucl.ac.uk">Gabrielle Hodge</a><br /> <em>With thanks to Ida Rogers, Joshua Sealy and the CoEDL Executive Committee</em></p> <p align="center"> <img width="500" src="images/ImprovingCommunicationAccess.gif" /> </p> <p><span style="font-variant:small-caps;">Last updated: 28 June 2021</span></p> <p><em>This working guide was motivated by feedback provided to CoEDL’s Education Committee about the possibility of improving the accessibility of our educational and other public-facing output for deaf and hard of hearing colleagues, and many other people who benefit from captioned content or sign language interpreting services. It is not an exhaustive description of options available, rather it offers some simple workflows for anyone who wants to create captioned content for recordings after-the-fact or to learn more about providing captions or sign language interpreting for in-person or virtual events. We welcome any feedback, questions or suggestions as we move to improve communication access at CoEDL. Please get in touch via the email addresses above.</em> <br /></p><hr style="border:1px solid grey" /> <p><br /> Deaf and hard of hearing people have historically been marginalised in academia, and deaf signing people even more so. It is very difficult to request, organise and facilitate effective communication access if you need to use captions and/or a sign language. There are many factors that make this situation difficult. As an example, imagine you are a deaf signing academic, other professional or community member wanting to attend a seminar on a topic relevant to your research and/or community. You must first email the seminar organiser and ask about what (if any) communication access will be provided, and/or set the process in motion for organising your own access.</p> <p>Responses can vary, but it is common to receive a response such as, <em>“Sorry, we don’t have the funds, there’s no budget line for this,”</em> and no further engagement. A particularly negative and resistant response can involve upwards of twenty emails as the deaf person seeks to explain and justify why they belong at this seminar, and how they can participate. Or it can involve no response at all. Even a positive response will often come with lots of invisible labour in teaching organisers how to work with sign language interpreters, and dealing with various hiccups that come with learning any new process. From the perspective of a deaf person, it won’t be the first nor the last time this happens. These responses are experienced over and over again in different spaces and with different people. Sometimes access is provided, but only after a long and unnecessary battle. Unfortunately, many people experience burn-out and give up along the way. As solutions can often eventually be found, this suggests the main barrier relates to attitudes more so than budgets.</p> <p>Some of these responses may feel reasonable from an institutional and bureaucratic perspective, but it does not feel reasonable from a personal and individual one. The prevailing ideology is that communication access is too expensive, which means that deafness and deaf or hard of hearing people are treated as financially unsustainable. This is exhausting and harmful to both the deaf person and the academy as a whole. Over time, the cumulative effect is that deaf people and sign languages are not welcome in academic spaces. If the deaf academic or deaf participant is Aboriginal or Torres Strait Islander or from any other underrepresented group who has not historically participated in academia, these issues will be compounded by other barriers resulting from structural racism and other forms of systemic oppression. The result will be that deaf and hard of hearing signing people do not participate and everyone misses out.</p> <p>As academics committed to equitable and democratic scholarship, we need to consider the impact that various institutional practices and norms can have on different people who want to participate. Many barriers can be removed by understanding what different forms of discrimination look like and how they can be avoided. This working guide is not exhaustive, as it focuses only on communication access for deaf and hard of hearing people. It is important to recognise that facilitating communication access is not just a response to one individual at one meeting or event. In time, many people will benefit as barriers are removed and the space becomes more equitable. <br /></p><hr style="border:1px solid grey" /> <h3 id="captioning-options-to-improve-accessibility-of-your-audio-visual-content"> <a href="#captioning-options-to-improve-accessibility-of-your-audio-visual-content" class="anchor-heading" aria-labelledby="captioning-options-to-improve-accessibility-of-your-audio-visual-content"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Captioning options to improve accessibility of your audio-visual content </h3> <p><br /></p> <h4 id="some-terms-used"> <a href="#some-terms-used" class="anchor-heading" aria-labelledby="some-terms-used"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Some terms used </h4> <ul> <li><strong>Closed captioning vs open captioning</strong>: Closed captions are ones that you can choose to display or not display. YouTube videos will often have CC options, as does Netflix. Open captions are those that cannot be removed from the display. An example is if you have created a subtitled video and burned the text into the video footage(this process will be described below).</li> <li><strong>Automatic captioning</strong>: Auto-captioning uses AI (artificial intelligence) to process the speech to text. YouTube uses this technology (this will be discussed below), as do apps that you can use on your computer or smartphone.</li> <li><strong>Captions vs transcriptions</strong>: Captions are typically presented at the bottom of the video, transcriptions can be provided in a separate file as text, of it can be displayed in a side panel, but not in the video, itself.</li> </ul> <h4 id="what-type-of-access-could-be-offered-and-when"> <a href="#what-type-of-access-could-be-offered-and-when" class="anchor-heading" aria-labelledby="what-type-of-access-could-be-offered-and-when"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What type of access could be offered and when? </h4> <ol> <li><strong>Captioning pre-recorded content:</strong> <ul> <li>When lectures, meetings, seminars, or workshopsare recorded live and with no deaf people or others needing captions presentin the audience, these presentations can becaptioned after the event and made available to the public.</li> <li>Pre-recorded videos presented at a conference can be captioned prior to sending to conference organisers. Making a captioned version available would greatly improve access to your content.</li> </ul> </li> <li><strong>Live captioning and/or interpreting:</strong> When deaf or hard of hearing colleagues want to access and participate in live lectures, meetings, seminars, or workshops, you should make sure they have access to one or both of the following <em>(these services may be provided by the participant’s home institution, but this should not be assumed, as affiliation does not guarantee access)</em>: <ul> <li><strong>Live captions or transcriptions (onsite or remote):</strong> Captions or transcriptions created by a human which can be done onsite or remotely. One method is referred to as <em>STTR (Speech-to-Text Relay)</em> in Australia and the UK. Another method is <em>CART (Communication Access Real-Time Translation)</em> in the USA. Both terms refer to the same output. The methods used to achieve either may be different, e.g., stenograph versus respeaking, which can affect the quality of captions produced. The output may be presented as captions or a transcription projected onto a screen, and/or sent directly to the laptop of the participant. However, it is important to realise that deaf and hard of hearing participants are often excluded from participating in discussions or question/answer sessions when using captions. This is because there is a delay between what is spoken and what is captioned, and/or when there is no option for deaf and hard of hearing participants to respond via typing text, and/or when they prefer to sign rather than type text. Moderators need to be aware there will be a delay, and check if anyone relying on captions needs clarification or wants to contribute.</li> <li><strong>Sign language interpreters:</strong> Qualified sign language interpreters can be booked to provide access for signing deaf people who use interpreters. A major benefit is that interpreters facilitate two-way interaction in real time, enabling everyone to access each other. Captions will only work one-way between people with sensorial asymmetries, e.g., between people who do not sign and deaf people who do not speak. Sign language interpreting is a very personal process and quality can vary widely. It is a good idea to liaise directly with the deaf person to find outwhat language, service and interpreters they prefer to use. See <a href="https://paradisec-archive.github.io/PARADISEC_workflows/10_improving_communication_access.html#providing-interpreters-who-can-work-between-signed-and-spoken-languages">below</a> for more information on booking and working with sign language interpreters.</li> </ul> </li> </ol> <h4 id="how-to-caption-pre-recorded-content"> <a href="#how-to-caption-pre-recorded-content" class="anchor-heading" aria-labelledby="how-to-caption-pre-recorded-content"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How to caption pre-recorded content </h4> <h5 id="creating-captions-using-youtube"> <a href="#creating-captions-using-youtube" class="anchor-heading" aria-labelledby="creating-captions-using-youtube"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Creating captions using YouTube </h5> <p><br /> Below is a video that instructs you in creating captions for media using YouTube’s AI (Artificial Intelligence) process <em>as a starting point</em>. The steps outlined in the video:</p> <ul> <li>Upload video to your YouTube page (you need to have a YouTube account)</li> <li>YouTube will create captions automatically, usually within a few hours</li> <li>Using YouTube Studio from your account page, you will edit any mistakes made by YouTube’s AI process</li> <li>Check the appropriateness of the caption alignment and amount of words on the screen, making sure the captions easy to read</li> <li>Introduce each new speaker in the captions, e.g. <code class="language-plaintext highlighter-rouge">[SPEAKER: Dr. Smith] Thank you for inviting me today.</code></li> <li>Download your newly corrected captions as .srt file</li> <li>Combine captions with your video using the free software <a href="https://handbrake.fr/">Handbrake</a> <br /></li> </ul> <p align="center"> <iframe id="video" width="560" height="315" src="https://www.youtube.com/embed/MQMdm6BYAJo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe> </p><hr style="border:1px solid grey" /> <h5 id="options-for-live-captioning-of-online-event"> <a href="#options-for-live-captioning-of-online-event" class="anchor-heading" aria-labelledby="options-for-live-captioning-of-online-event"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Options for live captioning of online event </h5> <h6 id="captions-by-ai--artificial-intelligence"> <a href="#captions-by-ai--artificial-intelligence" class="anchor-heading" aria-labelledby="captions-by-ai--artificial-intelligence"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Captions by AI -Artificial Intelligence </h6> <ul> <li><strong>Zoom</strong> does have the option for the host of a meeting to engage the live captioning AI tool; <strong>however</strong>, this is dependent upon your institution’s license with Zoom. <em>At this time, ANU is in negotiations with Zoom to secure a new license, which would include this feature. Check with your versions of Zoom and if it is not a feature you can use, contact your institution’s IT department (those responsible for Zoom) or your Accessibility Services team and lodge a request. This is no guarantee you will get this feature-but providing feedback to your institution will be helpful.</em></li> </ul> <p><em>For more information on how this works:</em> <a href="https://support.zoom.us/hc/en-us/articles/207279736-Closed-captioning-and-live-transcription">https://support.zoom.us/hc/en-us/articles/207279736-Closed-captioning-and-live-transcription</a></p> <ul> <li><strong>Zoom + Otter.ai</strong> is another method of live transcribing during a meeting, using artificial intelligence. Zoom allows for 3rd party software to perform auto-generated transcripts; this occurs in a separate text box, not as captions within the video window. If your institution does not provide this software to staff, there is a subscription for use. Otter’s Business Plan includes live captions for Zoom.</li> </ul> <p><em>See University of Melbourne’s findings on accuracy of Otter.ai’s auto-transcripts:</em> <a href="https://www.unimelb.edu.au/accessibility/tutorials/zoom/zoom-meetings-and-automatically-generated-transcriptsg">https://www.unimelb.edu.au/accessibility/tutorials/zoom/zoom-meetings-and-automatically-generated-transcripts</a></p> <ul> <li><strong>Microsoft Teams</strong> also has a live captioning feature for meetings held within the MS Teams App.</li> </ul> <p><em>See University of Melbourne’s findings on accuracy of MS Teams auto-captioning:</em> <a href="https://www.unimelb.edu.au/accessibility/video-conferencing-for-hearing-impaired-staff/auto-captioning">https://www.unimelb.edu.au/accessibility/video-conferencing-for-hearing-impaired-staff/auto-captioning</a> <br /></p> <div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note: Things to keep in mind:</b> <br /><br /> 1. For it to be useful, you should have a good microphone, the speaker needs clear pronunciation, the participants need to observe good sequential turn taking, and there should be limited background noise <br /><br /> 2. AI captioned output will have many mistakes, perhaps even so many that the content is no longer accurate or useful <br /><br /> 3. AI software may have subscriptions that are not covered by your institution”</div> <blockquote> <p><strong>Things to keep in mind with AI auto-captioning</strong></p> <ol> <li>For it to be useful, you should have a good microphone, the speaker needs clear pronunciation, the participants need to observe good sequential turn taking, and there should be limited background noise</li> <li>AI captioned output will have many mistakes, perhaps even so many that the content is no longer accurate or useful</li> <li>AI software may have subscriptions that are not covered by your institution <br /></li> </ol> </blockquote> <h6 id="live-human-captioning-during-online-meeting"> <a href="#live-human-captioning-during-online-meeting" class="anchor-heading" aria-labelledby="live-human-captioning-during-online-meeting"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Live human captioning during online meeting </h6> <ul> <li><strong>CART</strong> <em>(Communication Access Real-Time Translation)</em>** or <strong>STTR</strong> <em>(Speech-to-Text Relay)</em> is a service where a trained stenographer is either on-site or at a remote location listening to the speech and types the captions in real time. This is the method used to create transcripts of live court proceedings. However, some CART or STTR services (often for remote captions) are provided via re-speaking technologies, where a person listens to the speech and respeaks it more clearly for the AI recognition technology, which creates the captions. Stenography is a far more accurate method for live captioning.</li> <li>Zoom has a feature which allows someone designated by the host to type in what is being said, and this can be seen as closed captions to anyone in the meeting who wishes to view it.</li> </ul> <blockquote> <p><strong>Things to keep in mind with live-captioning</strong></p> <ol> <li>CART or STTR option will have increased the quality of your transcriptions, but it will be costly, as you are paying for a trained service provider to type in captions during your event</li> <li>CART or STTR can be provided by an on-site captioner or remotely. Remote caption services are often cheaper. However, you need to weigh up the benefits for the people requiring access for the meeting</li> <li>It is a good idea to talk with the people requiring access to work out the best solution for the specific context</li> <li>Deaf and hard of hearing participants are often excluded from participating in discussions or question/answer sessions when using captions. This is because there is a delay between what is spoken and what is captioned, and/or when there is no option for deaf and hard of hearing participants to respond via typing text, and/or when they prefer to sign rather than type text. Remember there will be a delay and check if anyone relying on captions needs clarification or wants to contribute <br /></li> </ol> </blockquote> <h3 id="providing-interpreters-who-can-work-between-signed-and-spoken-languages"> <a href="#providing-interpreters-who-can-work-between-signed-and-spoken-languages" class="anchor-heading" aria-labelledby="providing-interpreters-who-can-work-between-signed-and-spoken-languages"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Providing interpreters who can work between signed and spoken languages </h3> <p>There are many different situations in which you may need to book sign language interpreters. You may have invited a deaf academic from Australia or overseas. You may have received a request from a deaf member of the public to attend a seminar or event. You may be hosting an event on a topic related to deafness, deaf people and sign language and seek to make it accessible for the wider deaf community. Different situations may require different processes for booking sign language interpreters.</p> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
