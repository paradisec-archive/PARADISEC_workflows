{"0": {
    "doc": "Getting Started with PARADISEC",
    "title": "Getting Started with PARADISEC",
    "content": ". Last updated: 7 July 2021 . This page is dedicated to helping you begin the process of getting your materials organised and eventually archived with PARADISEC (Pacific and Regional Archive for Digital Sources in Engangered Cultures). STEP 1: Sign up as a user with PARADISEC . Signing up with PARADISEC means you become a PARADISEC user. As a user you can access data in an open-access collections after agreeing to PARADISEC’s conditions of access, or you may send a request to access data that has restrictions on viewing by following instructions provided by the collector on their catalog page. You also need to sign up with PARADISEC if you wish to deposit material to the archive. The process of signing up is simple- go to the PARASDISEC catalog web page: http://catalog.paradisec.org.au/, and click on Sign up in the upper right‐hand corner. Once you sign up, you get an automated message informing you to check your email to confirm your account, . “A message with a confirmation link has been sent to your email address. Please open the link to activate your account” . Click on the link in your email to confirm. Congratulations, you are now a PARADISEC user! It is recommended that you browse the collections held in PARADISEC so that you can investigate the different ways collections can be organised. Below are a some examples: . | PhD thesis: OE1 is a collection of narratives and wordlists that the depositor used in writing their PhD thesis. This includes the segmented audio files that are linked to the exemplar utterances within the thesis. | Field methods course: The MEU1 collection holds all recordings generated during a field methods course. Note how the different type of events (classroom recordings vs breakout sessions) are kept together by the nature of the item names. | Separate collections for each language/dialect/variety: Explore two of this depositor’s 27 collections, SDM42 and SDM45. Each of these collections feature one language variety. There is no limit as to how many collections you can create. | Many languages in one collection: In the DD1 collection, the depositor has included recordings of over 25 languages, collected since 2010. This collection is still growing! | . STEP 2: Contact PARADISEC to help you create a new collection . Only PARADISEC administrators can create a collection in the catalog. When you are ready for us to create a collection, contact the PARADISEC administration at admin@paradisec.org.au or the CoEDL Data Manager. To begin with you will need to provide us with the following information: . | Collection ID | A brief title of your collection | A more detailed description of your collection | Funding body (if applicable) (e.g. ARC, ELDP, etc.) | Grant identifier (if applicable) (e.g. CoEDL = CE140100041 or Wellsprings = FL130100111) | . Preliminary exploration of your files . Before you contact PARADISEC, take a look at your files and determine how you want your collection(s) presented. Do you need one collection? Or more than one? This is the time for you to reflect upon how you want your material organised in the archive. Information to provide to PARADISEC . Once you have decided upon which files you would like to archive, come up with a name and description for your collection. As for the Collection ID, PARADISEC administrators can help you come up with this- the collection ID should be a unique identifier (could be your initials in all caps and a digit, or the ISO language code). Example collection IDs: JM1, JCM4, OE1, MEU1, etc. The digit is required and it distinguishes your collection from that of someone with the same initials (John Mansfield, Julia Miller, etc), but also allows for multiple collections, should you require, e.g. JM1, JM2… JM85. STEP 3: Organise materials to be sent to collection . PARADISEC’s metadata spreadsheet . PARADISEC has created a spreadsheet that allows us to automatically create the catalog metadata for items in your collection. You can acces the spreadsheet here. (If the .xlsx file does not download automatically, then right-click on the link to save the file). Please do not alter the structure of the spreadsheet, as this will prevent the auto-upload process for us. Once your collection has been created, and has been populated with the metadata for your items, you can edit you collection information directly via the catalog pages. You can add details such as: . | your institutional affiliation | alternate names of the language(s) | you can set the map by zooming in on the map feature and selecting an area, or set it automatically by selecting the country or language | you can define/change access conditions | you can even assign editor privileges to a colleague or research assistant to help you update the collection’s metadata | . PARADISEC’s file naming conventions . Now comes the thrilling task of making sure your files are named appropriately. Getting your file names in order should come after you have created your collection and after you have settled on the organisation of your items (recording events) within your collection. ANATOMY OF A PARADISEC FILE NAME Say you have, for example, a file that you named 20150908‐wordlist‐01.wav while in the field. This in‐field naming convention includes the date in ISO format (YYYYMMDD). The (‐wordlist) marks this as being from a session involving wordlist elicitation. The (‐01) indicates that this is the first track of the session. You will have your own conventions. The name 20150908‐wordlist‐01.wav does not fit with the PARADISEC naming conventions. First of all, there needs to be a collection ID followed by a hyphen, and then only two more parts separated by hyphens: CollectionID-ItemID‐ContentFile. | CollectionID is your PARADISEC collection ID and it typically has the shape of your initials in capital letters and a number. This ID can be determined by you, but must be confirmed as available for use by the CoEDL Data Manager or a PARADISEC administrator. This ID is created when you set up a collection in PARADISEC. Mine could be JCM1 . | ItemID is your PARADISEC item ID. An item could be a cassette tape, or now in the born-digital age, it is typically an recording event containing all related files from that session- audio, video, transcriptions). You must use a terse description here. You may use an underscore ( _ ) if you need a separator; hyphens ( ‐ ) are prohibited within your Item ID as they are reserved PARADISEC operators. You could have speaker initials in your item name (JB), description of the task (wordlist), field site (BIMA). | ContentFile is the final necessary part to a file name. This part of the name allows you to enumerate files of the same format, i.e. photos with 001, 002, etc, or multiple tracks of a single audio or video session. You can distinguish type of microphone used for an audio track in this part of the file name, e/g/ -LM (lapel mic) or -HM (for head mounted mic). So if your original file was named 20150908‐wordlist‐01.wav, you could try something like this: JCM01‐20150908_wordlist‐01.wav . | . Note: Even if your item contains only one file, and thus does not need to be differentiated from other files in the item, you still need to have this third part of the file name. You could use -00, -01, -wordlist01, -original, etc. TEMPLATE: [CollectionID] - [ItemID] - [ContentFile] . file extension . | Coll ID | Item ID | Content | Extension | . | JCM01 | 20150908_wordlist | 01 | .wav | . Note: No spaces or special characters are allowed in your file names, and only the two hyphens seen above are allowed. Underscores are fine. File names should not exceed 30 characters, excluding file extensions. PARADISEC’s deposit form . And lastly, you need to fill out a deposit form that provides PARADISEC with your contact information, access conditions for your collection, including any restrictions. Fill in the form, sign it, scan or photograph it, and email it back to us. We keep this digital record with your collection. STEP 4: Send your files to PARADISEC . If you are planing to archive digital files with PARADISEC, and your institution is part of the Australian Access Federation (AAF), you can sign up for a Cloudstor account. Once you do, you get 1TB of free storage available to you instantly. You can also send us OneDrive, Dropbox, Google Drive links. These options are the best means to transfer files to PARADISEC. If you do not use any of those cloud storage options, but would like to transfer your files this way, contact PARADISEC or the CoEDL Data Manager and we can create a Cloudstor folder for you to use for transferring files to us. If uploading files to a cloud service is not possible due to a lack of computer access or poor internet connections, you can post a hard drive of your materials to PARADISEC at: . PARADISEC Room 3019, Sydney Conservatorium of Music C41 The University of Sydney NSW 2006 AUSTRALIA . Or to the CoEDL Data Manager at: . ATTN: CoEDL Data Manager The ARC Centre of Excellence for the Dynamics of Language College of Asia Pacific The Australian National University Coombs Building, 9 Fellows Road Acton 2601 ACT AUSTRALIA . Back to top . ",
    "url": "http://localhost:4000/02_getting-started.html#getting-started-with-paradisec",
    "relUrl": "/02_getting-started.html#getting-started-with-paradisec"
  },"1": {
    "doc": "Getting Started with PARADISEC",
    "title": "Getting Started with PARADISEC",
    "content": ". | Getting Started with PARADISEC . | STEP 1: Sign up as a user with PARADISEC | STEP 2: Contact PARADISEC to help you create a new collection . | Preliminary exploration of your files | Information to provide to PARADISEC | . | STEP 3: Organise materials to be sent to collection . | PARADISEC’s metadata spreadsheet | PARADISEC’s file naming conventions | PARADISEC’s deposit form | . | STEP 4: Send your files to PARADISEC | . | . ",
    "url": "http://localhost:4000/02_getting-started.html",
    "relUrl": "/02_getting-started.html"
  },"2": {
    "doc": "Metadata & Data Management",
    "title": "Metadata &amp; Data Management",
    "content": "🚧 This page is currently under construction 🚧 . Last updated: 5 July 2021 . Most of this information is geared toward preparing your collection for PARADISEC (Pacific and Regional Archive for Digital Sources in Engangered Cultures), but some of the organisational concepts can be applied to depositing with other archives such as The Endangered Language Archive (ELAR) or The Language Archive (TLA). Metadata management tools . At this time there are two metadata tools that we are supporting. LaMeta is still being improved with each new version, so some newly added features may not function as expected (such as the PARADISEC export function). Follow the links below to get the most recent versions. PARADISEC-configured Spreadsheet . Right-click on this link to save the PARADISEC pre-configured spreadsheet. All fields necessary to create catalog items in PARADISEC are included. Note: Rows in the PARADISEC spreadsheet are meant to capture metadata at the level of an item, or recording session. Do not list individual file information. LaMeta . This free software will allow you to create .imdi metadata files via a simple graphical interface. Follow this link to download the latest version. If you need guidance using LaMeta, take a look at this helpful site. The LaMeta metadata export lends itself for archiving with ELAR; however, there is an option to export the project metadata in a CSV that is formatted for PARADISEC. This funtion is in the early stages and your export may require some cleaning up. Back to top . ",
    "url": "http://localhost:4000/03_data_management.html#metadata--data-management",
    "relUrl": "/03_data_management.html#metadata--data-management"
  },"3": {
    "doc": "Metadata & Data Management",
    "title": "Metadata & Data Management",
    "content": ". | Metadata &amp; Data Management . | Metadata management tools . | PARADISEC-configured Spreadsheet | LaMeta | . | . | . ",
    "url": "http://localhost:4000/03_data_management.html",
    "relUrl": "/03_data_management.html"
  },"4": {
    "doc": "Suggested specifications for digital capture",
    "title": "Suggested specifications for digital capture",
    "content": "🚧 This page is currently under construction 🚧 . Last updated: 5 July 2021 . Audio recordings . Video recordings . Back to top . ",
    "url": "http://localhost:4000/04_suggested_specifications.html#suggested-specifications-for-digital-capture",
    "relUrl": "/04_suggested_specifications.html#suggested-specifications-for-digital-capture"
  },"5": {
    "doc": "Suggested specifications for digital capture",
    "title": "Suggested specifications for digital capture",
    "content": ". | Suggested specifications for digital capture . | Audio recordings | Video recordings | . | . ",
    "url": "http://localhost:4000/04_suggested_specifications.html",
    "relUrl": "/04_suggested_specifications.html"
  },"6": {
    "doc": "Digitising Manuscripts & Field Notebooks",
    "title": "Image Capture and Post-production Editing Workflows for PARADISEC Archive",
    "content": ". Last updated: 5 July 2021 . This page outlines PARADISEC’s approach to digitising text materials. The majority of our fieldnotes, papers, and notebook digitisation is done with high resolution photography, not scanning. Here are some reasons why we choose to use photography rather than scanning: . | the process is much faster | items that are very fragile or have different shapes are easily accomodated with less handling | this method will capture very high quality images with correct colour representation | the equipment is portable and can easily be set up in most environments, including remote field locations with tricky power options | depending on your equipment choices, this can be the least expensive option, yet will still retain high quality output | . Target format of images to be archived in PARADISEC . Before discussing the details of equipment we use in this workflow, here are the target file formats for image capture and archiving and the quality standards we request. Adhering to these high standards may be difficult in some situations; please try to aim for these as best you can. |   | Capture file format | Archival copy | Access copy | . | File type | .CR2 (RAW) | .tif | .jpg | . | DPI | 72 | 400 | 300 | . | Bits/Channel | 16 bit | 8 bit | 8 bit | . | Colour mode | RGB (Adobe RGB (1998) | RGB | RGB | . Note: The above 72 DPI (dots per inch) figure for the raw image is not very revealing as to the image quality compared to the 400 or 300 DPI figures. Image quality actually has more to do with pixel dimension. If you wish to read up on why DPI can be a tricky standard, take a look at this article: The myth of DPI. There will be more about target image sizes (pixel dimension) below in the section on workflow and remote capture settings. In the end, we would only need the .tif version from you for the archive. Our system automatically creates the access .jpg. If you are archiving images of notes or a field journal, it is a good idea to also provide a single .pdf of the images digitally bound together. For this, you should use compressed .jpgs rather than .tifs, which will keep the size of the .pdf manageable. Equipment used in this guide . | Equipment | Description and links to more details | . | Cameras | Canon Powershot G12 (compact digital camera) and Canon EOS 700D (DSLR) | . | Photo stand | Kaiser Reprokid | . | Tripod with Reversable centre post | Velbon Sherpa 803R Pro Tripod | . | Shelf clamp | Velbon Clamp Kit II | . | Software for remote capture | EOS Utility (for compatible Canon cameras) | . | Software for post-production editing | Adobe Bridge | . NOTE: The above information and the workflow included on this page are provided as suggestions based on PARADISEC-specific workflows; feel free to choose your own hardware and software. Cameras . Canon PowerShot G12 . This Canon camera was purchased in 2010 and it is still fully functional in 2021. It is a compact digital camera, not a DSLR. The PowerShot allows you to capture RAW images without JPEG compression, as well as JPEGs, or both simultaneously. This model does not allow for tethering without some hacking of the firmware. I have not done this hack; See below for a simple workflow for image capture without tethering your camera to a computer. The PowerShot G12 features an articulated LCD screen. This means you can rotate it so that your target image is visible from a seated position when the camera lens is pointed downwards on a desk or table in front of you. Canon EOS 700D . This DSLR does allow remote capture tethering. This opens up the possibility of attaching the camera to a computer to view, focus, and capture images and store them directly on your computer, with a predertermined file-naming pattern. But you can also use the same workflow as the non-tethering compact digital camera if you do not have a computer handy at the time of digitising. This model also features an articulated LCD monitor for comfortable image viewing. Another bonus with this camera is that you can do quick zoom adjustments by manually adjusting the lens, which you cannot do with the PowerShot. Tripods and photo stands . Velbon Sherpa 803R . This tripod was purchased about ten years ago, so it is unlikely that you would find the same model; however, the important features on this tripod are the following: . | reversable centre post (necessary for this workflow) | relatively compact and lightweight | spirit level (not necessary, but nice to have) | . Setting up the tripod with reversable centre post . This is the least expensive and most versatile setup, especially if you need to photograph items in a remote location. The tricky part is getting the lighting right. Your light source (natural or artificial) could be blocked by the tripod legs and cast a shadow on your image. If your light source is in a fixed position, try moving the tripod around to minimise any shadows. You may also try to find lights that you can clip on to the legs of your tripod or onto nearby furniture. Just be mindful that too much direct, unfiltered lighting may wash out your image. If you can place the tripod next to a light coloured wall and then shine the lights onto the wall. The reflected light may be enough to provide evenly disrtributed indirecrt lighting. Velbon shelf clamp . The Velbon tripod mentioned above came with a shelf clamp, but you can purchase a clamp separately. If you do, make sure there is a tripod post that comes with the clamp if you do not already have a tripod with a removable centre post. The link in the table above directs you to a similar model to the shelf clamp that came with the Velbon Sherpa 803R. Setting up the shelf clamp . Using just the shelf clamp and the tripod’s centre post is by far the simplest combination, especially if there is any travel involved. The only drawback is that this requires a shelf that you can clamp to. However, if you are in a very remote location you could construct something with timber, bamboo, or even a smooth, sturdy branch. Just make sure it is strong and secure enough to hold your camera and allows you to create consistant images. Below are two configurations with the shelf clamp. The image on the left is with the Canon EOS 700D tethered to a laptop for remote capture. The image on the right is the Canon PowerShot; images are being captured to the camera’s SD card. Kaiser Reprokid Photo Stand . The Reprokid model is a compact camera stand that can accommodate small, lightweight cameras. It works really well with either of the above Canon cameras. This photo stand came with the lighting set, so one does not need to figure out where to attach any lighting. The vertical post is ruled so you can retrieve the distance of the lens to the target, or just make note of the camera placement for quick set up the next time you shoot. The base is a hard plastic grey surface so I use black matte card stock under my items. You can place a ruler or a colour separation guide and grey scales patch on the base if you need this level of size or colour precision in your image capture. Setting up the photo stand . Photo stands have many benefits for image capture. This particular model has the lighting attached, as noted above you don’t have to worry about where to clamp the lights. The light fixtures on this stand can move around, so if the light is too direct and overpowering, they can turn so that they are pointing away or toward the back wall. Be mindful of the cables from the lights; if you don’t tie them up and out of the way, they can show up in an image, or cast a shadow on your subject. Having the camera attached to a stable, ruled post is great for keeping your set-up consistant from day to day. If you need to shift things around in your space, the entire set-up can be moved as is. Having a solid base on which to put your notebooks or documents is also a fine feature. The base on this model is a bit small. If you need to build up the base to create an expanded, level for larger notebooks to fit, perhaps place some books you may have nearby around the photostand’s base to create an enlarged, even platform. Or get a piece of plywood and clamp it to the photo stand base. The downside to using a photo stand is the cost. Pricing for these can be expensive. The Reprokid is one of Kaiser’s less expensive models and it works very well for our purposes. Software . EOS Utility . For remote capture: Use Canon’s EOS Utility with a compatible Canon camera Remote capturing images directly to your computer can speed up your task of taking photos, especially if you set up a good workflow. There are many tethering tools available. I have chosen EOS Utility because it came with my Canon EOS 700D, it was free, and it serves our purpose. Here is an article from Tether Tools (2020) that discuss other tethering software that is currently on the market. If you are planning to use a Canon camera that is compatible with the EOS Utility software, here are the links: . | EOS Utility for PCs | EOS Utility for Macs | . Note: The link to the PC version is for EOS Utility 3, which is not compatible with my EOS 700D camera; however, with this installation both EOS Utility 2 and EOS Utility 3 are installed. The version that I am using is 2.14.20.0. Adobe Bridge . For image preview and processing, use Adobe Bridge As you capture the images, it is important to check their quality before you get too far into your task. But even at the end of the day, when if you have collected hundreds of photos, you may realise that they would be better cropped, or that the lighting was too warm and you would like to cool down the colours, you can use Adobe Bridge to do this as a batch process. Adobe Bridge is available for free. You do not need to pay for it, but you do need to sign up with Adobe. Navigate to the Adobe Bridge download page. Workflow for remote capture . (This is specifically designed for ANU-PARADISEC workflows, but the concepts are easy enough to personalise for your own purposes) . | Start the computer and use your ANU UniID to log on | Take the Canon 700D battery pack from the charger and insert into the camera. | Once the computer is fully booted, turn the camera on. This will also open the EOS Utility software installed on the computer. Note: Make sure the AF/MF (Auto Focus, Manual Focus) setting on the lens of the camera is set to AF and that the camera mode on the top of the camera is set to TV . | Select “camera setting/remote shooting” from the start screen. A window with the camera settings will pop up on the right side of the screen. | Click on “Live View shoot…” as seen in the remote window above. This will open the window showing the full live view of what the camera is capturing. | Click on the folder icon (found toward the top of the remote, under the AF/MF switch) to select a destination folder. For collected items (folder, notebook, manuscript, etc.), create a new folder for each item. You will be saving these images directly to the folder you designate- not to the SD card in the camera. | To set up the file-naming for the images: . | Click on the folder icon and select “File Names” in the preference window | Click “Customize…” to customize the name. Create file names that start with a collection ID, followed by a hyphen, then the item number (what you have come up with as an ID for your notebook/folder/manuscript), and then select sequential numbering of the images, e.g. DT1-04-, Close the window. | In the menu window, set “Number of Digits” to 3, This will accommodate items with 999 pages. If there are under one hundred pages, use 2 digits. If over a thousand pages, use 4 digits. This will help with the ordering in PARADISEC collections and is just good practice. | Set “Start” to 1 at when you begin photographing each new item (otherwise it will just continue counting from whatever was shot in the previous session) | . | Fix the position of the item using the Live View window. Use the black card stock paper provided as a background and to cover the page that is not the target page. Switch on the attached lamps on the stand. | Set lighting by double-clicking on the relevant icon in the settings window. The lamp symbol (indicating tungsten lighting) is the best light setting for our studio. The shutter speed should be 1/125 and the ISO should be 200 for our studio lighting. If necessary, make finer adjustments to the exposure level (adjusts image lightness/darkness) by moving this digital slider either toward -1 or +1. | When the live view window shows what you would like to capture, either click on the round, black button in the top right corner in the remote window, or the small black button in the lower left side of the live view window, or press the space bar. Repeat this step for each page of your item. If you are capturing more than one item/notebook, then restart your workflow from step 6. Do not forget to reset your image naming and counting. | When finishing a session for the day, wait until the last image has loaded and then switch the camera off. | Remove the battery and put into the charger to charge for the next session. | . Post-production processing of images . The following instructions are based on Adobe Bridge CC 2021. Many of the functions are similar to the previous versions, with slight adjustments to the interface and workspaces. Note: If you are affiliated with ANU, our workstation allows you to access this program using your university login. Otherwise, you can learn more about accessing Bridge for free here: Adobe Bridge . You will be making small batch adjustments to the colour or lighting if necessary; this will be best if you restrict your editing to one notebook at a time as the colour of the paper may differ from notebook to notebook. Also, if you had to reshoot a page, or you accidentally shot a page twice, you will need to delete an image and rename your files. Once you have finished creating images, open Adobe Bridge and navigate to the folder containing your notebook images within Bridge. Highlight the images you want to edit, then go up to the top menu and select the camera lens icon; this will open the Camera Raw function within Bridge, where we will make our edits and create tifs. Once in the Camera Raw window, all the editing functions are in the right panel. Image below presents the colour and lighting editing options. You can edit a single image, or multiple images at once: . And in this image you can see the size and image orientation options, including cropping. Again, this can be done for a single image, or multiple images at once: . Once you are happy with your edits, you can batch export by selecting the small export icon (circled in image below), if you are wanting to export multiple files, select select all images you want to export, then press the export icon near the other editing options located in the right panel; otherwise you can export a single image by selecting the icon in the uper right corner of the image thumbnail. Your export settings for archiving with PARADISEC should be the following: . Additional resources . Butterworth, J., Pearson, A., Sutherland, P. &amp; Farquhar, A. (2018) Remote Capture: Digitising Documentary Heritage in Challenging Locations Open Book Publishers, Open Field Guides Series, vol. I doi:10.11647/OBP.0138 . Back to top . ",
    "url": "http://localhost:4000/05_digitising_manuscripts.html#image-capture-and-post-production-editing-workflows-for-paradisec-archive",
    "relUrl": "/05_digitising_manuscripts.html#image-capture-and-post-production-editing-workflows-for-paradisec-archive"
  },"7": {
    "doc": "Digitising Manuscripts & Field Notebooks",
    "title": "Digitising Manuscripts & Field Notebooks",
    "content": ". | Image Capture and Post-production Editing Workflows for PARADISEC Archive . | Target format of images to be archived in PARADISEC | Equipment used in this guide . | Cameras . | Canon PowerShot G12 | Canon EOS 700D | . | Tripods and photo stands . | Velbon Sherpa 803R . | Setting up the tripod with reversable centre post | . | Velbon shelf clamp . | Setting up the shelf clamp | . | Kaiser Reprokid Photo Stand . | Setting up the photo stand | . | . | . | Software . | EOS Utility | Adobe Bridge | . | Workflow for remote capture | Post-production processing of images | Additional resources | . | . ",
    "url": "http://localhost:4000/05_digitising_manuscripts.html",
    "relUrl": "/05_digitising_manuscripts.html"
  },"8": {
    "doc": "Audio Digitising",
    "title": "Audio Digitising of Analogue Tapes",
    "content": "🚧 This page is currently under construction 🚧 . Last updated: 5 July 2021 . This page outlines the technical workflow for audio digitising for the PARADISEC unit based at the Australian National University. This worlflow can be modified to accommodate other organisations in their specific digitising goals. Equipment . Computer workstation . The ANU PARADISEC studio utilises a high-performance DELL OptiPlex 7080 Tower PC workstation with the following specifications: . | SPECIFICATION | DETAILS | . | Memory | 32GB (4x8GB) | . | Processor | Intel Core i7-10700 (8-core, 16MB cache, 2.9GHz to 4.8GHz, 65W) | . | Drive | M.2 512GB Class 35 Solid State Drive | . | Drive | 2.5in 1TB 7200 Hard Disk Drive | . | Drive | 8xDVD +/-RW 9.5mm Optical Disk Drive | . | Full-size Tower | SSF (Small Form Factor) will not accomodate necessary soundcard | . Soundcard: RME HDSPe AIO Pro . AD/DA Convertor: RME ADI-2 PRO FS . Audio cassette player: Tascam 122 mk II . Reel-to-reel tape player: Revox C270 . Software . Digitising Cassette Tapes . | Turn on computer and login with your ANU UDS credentials | . Recources you should find on your desktop: Wavelab Pro 10.0 shortcut Wavelab Pro 10.0 operations manual . | Turn on the RME ADI-2 PRO FS | Turn on and load a tape into the Tascam 122 mk II | Open the Wavelab program. | . You may need to select New Project if presented with a start-up window. Otherwise, the main Wavelab window will open up . Make sure the Workspace layout is the PARADISEC layout. Go to the banner menu at the top and select Workspace &gt; Layout &gt; PARADISEC . | Once main window opens, go up to the banner menu again and select File &gt; New. | . | Another window pops up asking you to select the template. Select PARADISEC. | . | A new timeline will appear in the AUDIOEDITOR window located in the lower half of the main window. In this window, select the ANALYZE tab along the top. Make sure to tick the radio button next to Audio Input | . From the meter tabs in the upper right quadrant of the main window, grab the PHASESCOPE and drag it out to create a popped-out, larger window. | look to the buttons on the bottom of the window | . Press the button with the dot on it, far right. This will open the following recording window and activate the PHASESCOPE: . | In Method tab under File to Create, select Named file from the drop down menu, then type in the file name you want to assign this file. Select the target location, E:\\DigitisedFiles for the output files. | Play the tape as a means to test the levels audio levels to recording. These can be seen in the Recording window. Play for a minute or so, making sure the signal stays below -12.00 dB. | . | If the signal on the tape is too loud, you should adjust this on the TASCAM using the OUTPUT dial on the far right of the tape machine. The dial should be on 8 to begin with. Make adjustments from there. | . | Once you adjust the volume, press the Reset button underneath the audio levels back in Wavelab so that you can confirm you have adjusted the audio adequately. | . | As you are previewing the tape, you can see that the PHASESCOPE is also actively monitoring the audio. We will use this scope to help guide us in our Azimuth adjustment. | You can find the Azimuth screw on the TASCAM machine in the gap right above where the word STOP button. It is the screw to the left of the heads. Use the supplied tiny screwdriver. | . | Look at the PHASESCOPE as you turn the screw to the left and to the right. Because you will be mostly digitising one-sided tapes, you want the line to be straight and along the Y-axis (vertical). If you were to digitise a reel-to-reel tape that is recorded on both sides, both sides are digitised simultaneously. As a result, there will be more of an X -shape of lines, representing each output of the tape. | . . | Once you get the cleanest, most vertical line you can, rewind the tape, press Record in Wavelab, then press play on the TASCAM and begin digitising the tape. Remain nearby to monitor the progress of this task; keep in mind that something could go wrong as the tape is being played. If you remain nearby you can | . Digitising Reel-to-reel Tapes . Additional Resources . Pragmatic Audiovisual Preservation (2021) Ashley Blewer . IASA Technical Committee, Guidelines on the Production and Preservation of Digital Audio Objects (2009, 2nd ed.) ed. by Kevin Bradley. Sound Directions: Best Practice for Audio Preservation (2007) Mike Casey &amp; Bruce Gordon . Back to top . ",
    "url": "http://localhost:4000/06_audio_digitising.html#audio-digitising-of-analogue-tapes",
    "relUrl": "/06_audio_digitising.html#audio-digitising-of-analogue-tapes"
  },"9": {
    "doc": "Audio Digitising",
    "title": "Audio Digitising",
    "content": ". | Audio Digitising of Analogue Tapes . | Equipment . | Computer workstation | Soundcard: RME HDSPe AIO Pro | AD/DA Convertor: RME ADI-2 PRO FS | Audio cassette player: Tascam 122 mk II | Reel-to-reel tape player: Revox C270 | . | Software | Digitising Cassette Tapes | Digitising Reel-to-reel Tapes | Additional Resources | . | . ",
    "url": "http://localhost:4000/06_audio_digitising.html",
    "relUrl": "/06_audio_digitising.html"
  },"10": {
    "doc": "Audio Processing",
    "title": "Audio processing of born-digital files",
    "content": ". 🚧 This page is currently under construction 🚧 . Last updated: 5 July 2021 . Back to top . ",
    "url": "http://localhost:4000/07_audio_processing.html#audio-processing-of-born-digital-files",
    "relUrl": "/07_audio_processing.html#audio-processing-of-born-digital-files"
  },"11": {
    "doc": "Audio Processing",
    "title": "Audio Processing",
    "content": ". | Audio processing of born-digital files | . ",
    "url": "http://localhost:4000/07_audio_processing.html",
    "relUrl": "/07_audio_processing.html"
  },"12": {
    "doc": "Video Processing - MP4 (H.264)",
    "title": "MP4 (H.264)",
    "content": "🚧 This page is currently under construction 🚧 . Creating .MP4 (H.264) videos with either ffmpeg or Adobe Media Encoder (CC 2018 or later) . Last updated: 5 July 2021 . Note: Always check the links to the software webpages for any substantial changes to installation instructions. PARADISEC adheres to the current best-practice standards for video archiving as set by the International Association of Sound and Audiovisual Archives (IASA). Using FFmpeg on a Mac . Installation . FFmpeg is an efficient and cost effective way to process video. It is done by using a Command Line Interface (CLI), but once the workflow is set up, it is relatively simple. If you are using a Mac, it is a bit more straight forward than the PC as Bash is a Unix shell (command language interpreter) and runs natively on Macs. To download FFmpeg, open a terminal window and first install Homebrew (command line package manager) with the following commands: . | Install Homebrew | . /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" . | Run Brew Doctor. This is a self-diagnostic tool to determine if everything is installed correctly. | . brew doctor . | Install FFmpeg | . brew install ffmpeg . To test if you have installed FFmpeg correctly, just type ffmpeg and enter. Information about the version of FFmpeg as well as enabled libraries should appear in your terminal window as seen in the image to the right. To view the FFmpeg manual in the terminal window, type in: . man ffmpeg . For further help using FFmpeg, take a look at the following sites: . FFmpeg . ffmprovisor . Navigate via terminal to your working directory . Transcoding .MP4 to .MP4 with ffmpeg . Using ffmpeg on a PC . Linux on Windows . Activating Linux on your PC . Installing Ubuntu . Installing ffmpeg via Ubuntu . Navigating to your working directory . Anatomy of the ffmpeg transcode command . Back to top . ",
    "url": "http://localhost:4000/08_video_processing_MP4.html#mp4-h264",
    "relUrl": "/08_video_processing_MP4.html#mp4-h264"
  },"13": {
    "doc": "Video Processing - MP4 (H.264)",
    "title": "Video Processing - MP4 (H.264)",
    "content": ". | MP4 (H.264) . | Using FFmpeg on a Mac . | Installation | Navigate via terminal to your working directory | Transcoding .MP4 to .MP4 with ffmpeg | . | Using ffmpeg on a PC . | Linux on Windows | Activating Linux on your PC | Installing Ubuntu | Installing ffmpeg via Ubuntu | Navigating to your working directory | . | Anatomy of the ffmpeg transcode command | . | . ",
    "url": "http://localhost:4000/08_video_processing_MP4.html",
    "relUrl": "/08_video_processing_MP4.html"
  },"14": {
    "doc": "Video Processing - MXF",
    "title": "MXF",
    "content": "Last updated: 5 July 2021 . This page outlines how to create lossless JPEG2000 .MXF videos using Adobe Media Encoder (CC 2018 or later). This is for digital-to-digital transcoding. Contact PARADISEC if you have analog material to digitise. PARADISEC adheres to the current best-practice standards for video archiving as set by the International Association of Sound and Audiovisual Archives (IASA). Define Encoding Settings - Making an Encoding Preset . The first thing we need to do is select the settings that we can use each time we want to create a lossless J2K .MXF video. To do this, we need to create an Encoding Preset. Go to the top Media Encoder CC menu to “Presets” and then select “Create Encoding Preset”. A new Preset window will open up. Look at the image below to see the settings you should choose. Each will be explained below. Preset name and format . First you should give the preset a meaningful name, I have chosen Lossless J2k (8-bit). The main reason for this particular name is to differentiate this preset from others you might use for different workflows (I will discus why I add the distinction 8-bit below). For the format, select JPEG 2000 MXF OP1a. Once you select this format, you are then offered these choices for the Based on Preset field: . You can leave the new default of RGBA 4:4:4:4 12-bit (BCs@L5). This value will change once we make further refinements in our settings. Leave the remaining settings in this section as their defaults (Comments field left blank, Export Video and Export Audio boxes ticked). Video settings . Edit only settings in the Video and Audio tabs. Settings in the other tabs (Effects, Captions, Publish) should be left untouched. Because we selected the JPEG 2000 MXF OP1a format above, the video codec will automatically be set to JPEG 2000 in this section. The basic video settings options will have changed to those appropriate for this format. Make certain Match Source is selected, this will automatically tick all the boxes below (if they are not already), retaining the same settings as those of the original file for the following fields Width, Height, Frame Rate, Field Order, and Aspect [ratio]. Chroma should be set to YUV 4:2:2 with a depth of 8-bit. In the rare case your original video has a colour depth of 10-bit, select the 10-bit option. To determine the bit depth of a video, use MediaInfo; the file’s bit depth is listed in the MediaInfo metadata output report. Note: If you are using CC2018: Set the Broadcast Profile to Level 6 (Lossless). This determines the maximum sampling and bit rates for the output file. You can see all the drop down choices offered below: . Note: If you are using CC2020: You need only tick the box for Lossless Compression; The Maximum Bitrate and Broadcast Profile automatically get set to 100,000 Mbps and Level 7 - 3200Mbps or Lossless, respectively . Audio settings . There are not many adjustments that need to be made to the audio settings (see image below). The Audio Codec will already be set to Uncompressed with a Sample Rate of 48,000 Hz. due to the choice of the video format of JPEG 2000 MXF OP1a. Make certain the Channels field is set to 2. If you are given a video that has been recorded with surround sound, there could be as many as 6 channels. Our standard is to have 2 channel stereo audio output for our .MXF files. 6 channel video files have caused problems for editing/playback in programs such as Adobe Premiere, etc. Then Set the Sample Size to 24 bit. The remaining settings . The remaining settings located underneath the tab area should all be left with the default settings (see image below). This means that the following boxes should all be left unticked: Use Maximum Render Quality, Use Previews, Set Start Timecode, and Render Alpha Channel Only. Leave the Time Interpolation set to Frame Sampling. This settings handles motion smoothing if you change the output file’s frames per second. Using MediaInfo to check your output file metadata . MediaInfo is the best method to access all of the file specifications you need in order to understand the structure of your media files. You should know the underlying specifications of your original file before you do any transcoding. This ensures that you are able to set your output settings to match the relevant specs of the original. Below is a side-by-side comparison of the MediaInfo outputs, with added red asterisks to highlight some of the specs to be aware of: . I have pulled out some of those specs for comparison in the table below. You will be creating a video that has an increased file size from the original; this is because the bitrate will have increased substantially due to the transcoding process for lossless .MXF. The durations need to be similar (within +/- 500ms). Unless you clear any changes in specifications with the depositor first, you will need to keep the following specs the same: aspect ratio, frame rate, color space, and bit depth. The audio channels may change from the original; an original video with six audio channels (surround sound) is problematic in Adobe. If the depositor requires the six channels to remain, this workflow will not handle it. Another one will need to be configured. Finally, the compression mode for the .MXF MUST indicate it is lossless. If it is not lossless, you need to look at your settings and try again. | SPECIFICATION | ORIGINAL .MTS | ARCHIVAL .MXF | . | Name | 00050.mts | 0005.mxf | . | Format | BDAV | MXF | . | Format profile | Blu-Ray Video | OP-1a v1.2 | . | File size | 31.5 MiB | 785 MiB | . | Duration | 37 s 350 ms | 37 s 440 ms | . | (Max.) Overall bitrate | 13.7 Mb/s | 176 Mb/s | . | Aspect ratio | 16:9 | 16:9 | . | Frame rate | 25 fps | 25 fps | . | Color space | YUV | YUV | . | Chroma subsampling | 4:2:0 | 4:2:2 | . | Bit depth | 8 bits | 8 bits | . | Compression mode | n/a | LOSSLESS | . | Audio channels | 2 | 2 | . | Sampling rate | 48 kHz | 48 kHz | . Once you transcode the original file to an .MXF, you will need to take a look at the .MXF file metadata to determine whether or not you have created an appropriate match to the original. Note: You can do this in batches, as MediaInfo allows you to open multiple files at one time. On a Mac, you get one MediaInfo window with a dropdown menu to select which file you want to see in the active report; on Windows, separate MediaInfo windows will open for each file selected. Using an MXF player to check the quality of your newly created file . Once you have checked the file metadata with MediaInfo, you will need to play through the entire video to see if there were any issues in your transcoding process. I have created a lossless .MXF that had playback issues, so this step in the quality checking process in very important. Unfortunately, there are not many players that can handle .MXF-formatted video. You need to find a player that lets you see if there is jumpy playback, dropped frames, or any other errors. Note: VLC can open and play .MXF files, but the playback is always jumpy, so you cannot determine if it is the player or your transcoding that is the source of the jumpy playback. This is not acceptable for our workflow. I suggest using Telestream’s Switch player. You can get a free trial, but the price for the basic player is under AU$15. With the basic license, the viewer will show the Switch watermark in the upper right corner of the video during playback of .MXF files, but this has no bearing on its functionality for our task, playback. Switch is not to be used in any transcoding or editing capacity. You can see in the upper left corner that there is some quality reporting. Pay special attention to the dropped frames. If there are any dropped frames, you will need to re-transcode the file. Note: If you are running other memory hungry programs in the background when you are trying to preview your .MXF with Switch, you will very likely have a report of dropped frames. You should quit all other processes while you are doing your playback reviews. Explanation of the Specifications used to create lossless MXF . | JPEG 2000 MXF OP1a is the MXF (Material Exchage Format) Operational Pattern 1a (OP1a), with lossles JPEG 2000 in a generic container (for more information see the Federal Agencies Digital Guidelines Initiative FADGI) . | YUV 4:2:2 with a depth of 8 bit is the Chroma Subsampling suggested by IASA for born-digital .MXF. Y (or often Y′) stands for the luma, or brightness, component; U and V are the two colour components. YUV colour encoding takes into consideration human perception thus creating an output that has masked any human-noticable distortions (for more information see YUV). | 4:2:2 denotes the vertical and horizontal subsampling (for more information read Charles Poynton’s work on Chroma subsampling HERE). | 8-bits per channel is typically the bit depth for many of the original .MOV, .MTS, .AVI, .MP4, etc. video files we handle. Using a 10-bit depth would needlessly increase the file-size while adding no improved quality. | Broadcast profile determines the maximum sampling and bit rates of the output file. Level 6 lossless (L6) is 520 Msamples/s and 1600Mbits/s. Level 7 lossless (L7) is 520 Msamples /s and and unspecified Max Bitrate. | For further information of the Media Encoder export settings mentioned above look HERE. | . Back to top . ",
    "url": "http://localhost:4000/09_video_processing_MXF.html#mxf",
    "relUrl": "/09_video_processing_MXF.html#mxf"
  },"15": {
    "doc": "Video Processing - MXF",
    "title": "Video Processing - MXF",
    "content": ". | MXF . | Define Encoding Settings - Making an Encoding Preset | Preset name and format | Video settings | Audio settings | The remaining settings | Using MediaInfo to check your output file metadata | Using an MXF player to check the quality of your newly created file | Explanation of the Specifications used to create lossless MXF | . | . 🚧 This page is currently under construction 🚧 . ",
    "url": "http://localhost:4000/09_video_processing_MXF.html",
    "relUrl": "/09_video_processing_MXF.html"
  },"16": {
    "doc": "Improving Communication Access",
    "title": "Improving communication access for deaf and hard of hearing people",
    "content": ". Developed by Julia Miller &amp; Gabrielle Hodge With thanks to Ida Rogers, Joshua Sealy and the CoEDL Executive Committee . Last updated: 28 June 2021 . This working guide was motivated by feedback provided to CoEDL’s Education Committee about the possibility of improving the accessibility of our educational and other public-facing output for deaf and hard of hearing colleagues, and many other people who benefit from captioned content or sign language interpreting services. It is not an exhaustive description of options available, rather it offers some simple workflows for anyone who wants to create captioned content for recordings after-the-fact or to learn more about providing captions or sign language interpreting for in-person or virtual events. We welcome any feedback, questions or suggestions as we move to improve communication access at CoEDL. Please get in touch via the email addresses above. Deaf and hard of hearing people have historically been marginalised in academia, and deaf signing people even more so. It is very difficult to request, organise and facilitate effective communication access if you need to use captions and/or a sign language. There are many factors that make this situation difficult. As an example, imagine you are a deaf signing academic, other professional or community member wanting to attend a seminar on a topic relevant to your research and/or community. You must first email the seminar organiser and ask about what (if any) communication access will be provided, and/or set the process in motion for organising your own access. Responses can vary, but it is common to receive a response such as, “Sorry, we don’t have the funds, there’s no budget line for this,” and no further engagement. A particularly negative and resistant response can involve upwards of twenty emails as the deaf person seeks to explain and justify why they belong at this seminar, and how they can participate. Or it can involve no response at all. Even a positive response will often come with lots of invisible labour in teaching organisers how to work with sign language interpreters, and dealing with various hiccups that come with learning any new process. From the perspective of a deaf person, it won’t be the first nor the last time this happens. These responses are experienced over and over again in different spaces and with different people. Sometimes access is provided, but only after a long and unnecessary battle. Unfortunately, many people experience burn-out and give up along the way. As solutions can often eventually be found, this suggests the main barrier relates to attitudes more so than budgets. Some of these responses may feel reasonable from an institutional and bureaucratic perspective, but it does not feel reasonable from a personal and individual one. The prevailing ideology is that communication access is too expensive, which means that deafness and deaf or hard of hearing people are treated as financially unsustainable. This is exhausting and harmful to both the deaf person and the academy as a whole. Over time, the cumulative effect is that deaf people and sign languages are not welcome in academic spaces. If the deaf academic or deaf participant is Aboriginal or Torres Strait Islander or from any other underrepresented group who has not historically participated in academia, these issues will be compounded by other barriers resulting from structural racism and other forms of systemic oppression. The result will be that deaf and hard of hearing signing people do not participate and everyone misses out. As academics committed to equitable and democratic scholarship, we need to consider the impact that various institutional practices and norms can have on different people who want to participate. Many barriers can be removed by understanding what different forms of discrimination look like and how they can be avoided. This working guide is not exhaustive, as it focuses only on communication access for deaf and hard of hearing people. It is important to recognise that facilitating communication access is not just a response to one individual at one meeting or event. In time, many people will benefit as barriers are removed and the space becomes more equitable. Captioning options to improve accessibility of your audio-visual content . Some terms used . | Closed captioning vs open captioning: Closed captions are ones that you can choose to display or not display. YouTube videos will often have CC options, as does Netflix. Open captions are those that cannot be removed from the display. An example is if you have created a subtitled video and burned the text into the video footage(this process will be described below). | Automatic captioning: Auto-captioning uses AI (artificial intelligence) to process the speech to text. YouTube uses this technology (this will be discussed below), as do apps that you can use on your computer or smartphone. | Captions vs transcriptions: Captions are typically presented at the bottom of the video, transcriptions can be provided in a separate file as text, of it can be displayed in a side panel, but not in the video, itself. | . What type of access could be offered and when? . | Captioning pre-recorded content: . | When lectures, meetings, seminars, or workshopsare recorded live and with no deaf people or others needing captions presentin the audience, these presentations can becaptioned after the event and made available to the public. | Pre-recorded videos presented at a conference can be captioned prior to sending to conference organisers. Making a captioned version available would greatly improve access to your content. | . | Live captioning and/or interpreting: When deaf or hard of hearing colleagues want to access and participate in live lectures, meetings, seminars, or workshops, you should make sure they have access to one or both of the following (these services may be provided by the participant’s home institution, but this should not be assumed, as affiliation does not guarantee access): . | Live captions or transcriptions (onsite or remote): Captions or transcriptions created by a human which can be done onsite or remotely. One method is referred to as STTR (Speech-to-Text Relay) in Australia and the UK. Another method is CART (Communication Access Real-Time Translation) in the USA. Both terms refer to the same output. The methods used to achieve either may be different, e.g., stenograph versus respeaking, which can affect the quality of captions produced. The output may be presented as captions or a transcription projected onto a screen, and/or sent directly to the laptop of the participant. However, it is important to realise that deaf and hard of hearing participants are often excluded from participating in discussions or question/answer sessions when using captions. This is because there is a delay between what is spoken and what is captioned, and/or when there is no option for deaf and hard of hearing participants to respond via typing text, and/or when they prefer to sign rather than type text. Moderators need to be aware there will be a delay, and check if anyone relying on captions needs clarification or wants to contribute. | Sign language interpreters: Qualified sign language interpreters can be booked to provide access for signing deaf people who use interpreters. A major benefit is that interpreters facilitate two-way interaction in real time, enabling everyone to access each other. Captions will only work one-way between people with sensorial asymmetries, e.g., between people who do not sign and deaf people who do not speak. Sign language interpreting is a very personal process and quality can vary widely. It is a good idea to liaise directly with the deaf person to find outwhat language, service and interpreters they prefer to use, see below for more information on booking and working with sign language interpreters. | . | . How to caption pre-recorded content . Creating captions using YouTube . Below is a video that instructs you in creating captions for media using YouTube’s AI (Artificial Intelligence) process as a starting point. Note: More information, including a .pdf version of the step-by-step process, can be found here: Creating Captions Guidelines . The steps outlined in the video: . | Upload video to your YouTube page (you need to have a YouTube account) | YouTube will create captions automatically, usually within a few hours | Using YouTube Studio from your account page, you will edit any mistakes made by YouTube’s AI process | Check the appropriateness of the caption alignment and amount of words on the screen, making sure the captions easy to read | Introduce each new speaker in the captions, e.g. [SPEAKER: Dr. Smith] Thank you for inviting me today. | Download your newly corrected captions as .srt file | Combine captions with your video using the free software Handbrake | . Options for live captioning of online event . Captions by AI -Artificial Intelligence . | Zoom does have the option for the host of a meeting to engage the live captioning AI tool; however, this is dependent upon your institution’s license with Zoom. At this time, ANU is in negotiations with Zoom to secure a new license, which would include this feature. Check with your versions of Zoom and if it is not a feature you can use, contact your institution’s IT department (those responsible for Zoom) or your Accessibility Services team and lodge a request. This is no guarantee you will get this feature-but providing feedback to your institution will be helpful. | . For more information on how this works: https://support.zoom.us/hc/en-us/articles/207279736-Closed-captioning-and-live-transcription . | Zoom + Otter.ai is another method of live transcribing during a meeting, using artificial intelligence. Zoom allows for 3rd party software to perform auto-generated transcripts; this occurs in a separate text box, not as captions within the video window. If your institution does not provide this software to staff, there is a subscription for use. Otter’s Business Plan includes live captions for Zoom. | . See University of Melbourne’s findings on accuracy of Otter.ai’s auto-transcripts: https://www.unimelb.edu.au/accessibility/tutorials/zoom/zoom-meetings-and-automatically-generated-transcripts . | Microsoft Teams also has a live captioning feature for meetings held within the MS Teams App. | . See University of Melbourne’s findings on accuracy of MS Teams auto-captioning: https://www.unimelb.edu.au/accessibility/video-conferencing-for-hearing-impaired-staff/auto-captioning . NOTE: Things to keep in mind with AI auto-captioning . | For it to be useful, you should have a good microphone, the speaker needs clear pronunciation, the participants need to observe good sequential turn taking, and there should be limited background noise | AI captioned output will have many mistakes, perhaps even so many that &gt; the content is no longer accurate or useful | AI software may have subscriptions that are not covered by your institution | . Live human captioning during online meeting . | CART (Communication Access Real-Time Translation)** or STTR (Speech-to-Text Relay) is a service where a trained stenographer is either on-site or at a remote location listening to the speech and types the captions in real time. This is the method used to create transcripts of live court proceedings. However, some CART or STTR services (often for remote captions) are provided via re-speaking technologies, where a person listens to the speech and respeaks it more clearly for the AI recognition technology, which creates the captions. Stenography is a far more accurate method for live captioning. | Zoom has a feature which allows someone designated by the host to type in what is being said, and this can be seen as closed captions to anyone in the meeting who wishes to view it. | . NOTE: Things to keep in mind with live-captioning . | CART or STTR option will have increased the quality of your transcriptions, but it will be costly, as you are paying for a trained service provider to type in captions during your event | CART or STTR can be provided by an on-site captioner or remotely. Remote caption services are often cheaper. However, you need to weigh up the benefits for the people requiring access for the meeting | It is a good idea to talk with the people requiring access to work out the best solution for the specific context | Deaf and hard of hearing participants are often excluded from participating in discussions or question/answer sessions when using captions. This is because there is a delay between what is spoken and what is captioned, and/or when there is no option for deaf and hard of hearing participants to respond via typing text, and/or when they prefer to sign rather than type text. Remember there will be a delay and check if anyone relying on captions needs clarification or wants to contribute | . Providing interpreters who can work between signed and spoken languages . There are many different situations in which you may need to book sign language interpreters. You may have invited a deaf academic from Australia or overseas. You may have received a request from a deaf member of the public to attend a seminar or event. You may be hosting an event on a topic related to deafness, deaf people and sign language and seek to make it accessible for the wider deaf community. Different situations may require different processes for booking sign language interpreters. Sign language interpreters . Qualified sign language interpreters work to simultaneously interpret between a spoken language (e.g., English) and a signed language (e.g., Auslan). They are language professionals akin to spoken language interpreters who work between two spoken languages. They have undertaken extensive training in language and interpreting. Some have also undertaken training in translation, although translation is historically the domain of deaf interpretersand translators. However, there is a key difference: interpreting between two spoken languages is usually done consecutively, whereas interpreting between a spoken and signed language is done simultaneously. It is important to recognise this because the demands of the interaction will be different and there is a higher chance for miscommunications that remain invisible to non-signers. As explained above, interpreters can be booked to provide access for signing deaf people who work with sign language interpreters to access spoken language events and enable non-signing speakers to access them in return. This is the major benefit of working with sign language interpreters ahead of captions: they facilitate two-way interaction in real time, enabling everyone to access each other. Unless the event moderator is very careful to ensure two-way participation see above, captions will often only work one-way between people with sensorial asymmetries, e.g., between people who do not know the sign language and deaf people who do not have speech privilege, and only as long as both share the same written language of the captions. Sign language interpreting is a very personal process and quality can vary widely. Interpreters may or may not be active members of the community to which the deaf participants belong. Here are some general guidelines: . | It is a good idea and collegial to liaise directly with the deaf participants to find out what service and interpreters they prefer to use. Sometimes they may prefer to organise and book their own interpreters, but this cannot be assumed. It may not be an option for the person. | It requires working far in advance than you may be used to, up to one month in advance, preferably earlier for large events and/or niche topics including academic presentations, which is a very specialised interpreting domain. Leaving it two weeks before the event will probably mean there are no interpreters available. Interpreters for academic situations often require preparation materials minimum two weeks in advance of the event to do their job effectively see below. | Depending on the situation, some deaf participants may be able to cover the cost of interpreting with their own funds. However, this cannot be assumed as it varies so widely according to country and individual. If the person has recourse to funds, they will usually tell you upfront. If there is no recourse to funds, you will need to arrange a budget. This may be via the central University body, Department or some other means. If you are organising a conference and there is no budget for communication access, you need to consider why this is the case. | It is important to work with interpreters who are registered with NAATI or equivalent professional bodies of the country of origin. Please check that the interpreters you are booking are registered professionals. | Sign language interpreters typically work in pairs. In Australia, the minimum cost will be for two interpreters for a two-hour assignment, although you can of course book two interpreters for shorter or longer durations. The interpreting team will switch roles every 15-20 minutes to assist with the cognitive labour of simultaneous interpreting. Some interpreters will accept bookings to work solo for up to one hour, as long as breaks are included and carefully monitored. However, this is usually negotiated on a case-by-case basis and only for small, one-to-one meetings, for example. It is not usually possible for dense academic presentations. | Consider how different contexts (e.g.,in-person versus virtual) can enhance or oppress communication between non-signing and signing people (who must visually attend to the interpreter while they are signing, and therefore cannot look at other things at the same time). The Deafness Cognition and Language (DCAL) research centre at UCL has published these helpful guidelines on managing online events that involve deaf signing people, sign language interpreters and/or captions: https://www.ucl.ac.uk/dcal/remote-working-guidelines | . Steps &amp; responsibilities involved in finding, booking &amp; working with interpreters . | Determining what communication access is required This includes finding out what language services are needed, e.g., Auslan/English interpreters, ASL/English interpreters, or some other language pair. Even if you are not organising and paying for the interpreting specifically, as the organiser of the event you will need to facilitate how communication access is provided, and this includes working with the interpreters to ensure the event runs effectively. Some large events, e.g., international conferences, may have different interpreting teams and language pairs. Often these events will require a designated Interpreter Coordinator to liaise between all and ensure cohesive service delivery. | Choosing and confirming interpreters This involves reaching out to different agencies or individual interpreters (if indicated as preferred or recommended by a deaf participant) to confirm the nature of the assignment, e.g.,whether it is a seminar or other event, and the topic of the assignment, as well as logistics such as the date and time. It is worthwhile establishing relationships with reputable interpreting agencies and interpreting professionals who can support this. Interpreters specialise in different areas, including academia. It is very important that you seek and receive confirmation of the booking. Do not assume that because you have put in a request that the assignment will be confirmed. Interpreters are in very high demand and sometimes it is not possible to book for those specific dates and times. You need to know this information as soon as possible in order to widen your search. | Sending preparation to interpreters This involves sharing any preparation materials with the confirmed interpreting team that can assist them in their work, e.g., draft slides, lecture notes, dot points, a publication, etc. This material enables interpreters to learn and orient effectively to the language and concepts you will be talking about. Typically, interpreters require this preparation material a minimum of two weeks before the event. They need time to read and digest it. They are working all day every day on other assignments like you, hence the need for preparation to be sent two weeks in advance. Of course, if it is a last-minute booking this will not be possible, but this is a general guide that will facilitate good relationships and communication access. Working with interpreters is also about building professional relationships, and indeed this is often how it works between individual deaf signing people and interpreters. | Receiving invoices and paying interpreters If you are covering the cost of interpreters and managing the finances of the event, you will receive an invoice from each interpreter after the event. You will need to pay this within the specified period. Late payments can damage professional relationships with interpreters. | . Services and Tools . | Expression Australia (Auslan interpreting, captioning, notetaking,transcription): https://www.expression.com.au/services/interpreting-and-captioning | The Deaf Society (Auslan interpreting): https://deafsociety.org.au/ | Ai-Media(Live CART captioning org): https://www.ai-media.tv/ | Otter.ai (AI captioning tool): https://otter.ai/ | . Other Helpful Links . | DCAL Remote Working guidelines for working with sign language interpreters on Zoom, etc: https://www.ucl.ac.uk/dcal/remote-working-guidelines | Automatic closed captioning with Zoom in use at the University College London: https://www.ucl.ac.uk/teaching-learning/news/2021/mar/zoom-licence-renewed-automatic-closed-captions-and-transcriptions-added | University of Melbourne articles on Auto-Captioning: . | https://www.unimelb.edu.au/accessibility/video-conferencing-for-hearing-impaired-staff/auto-captioning | https://www.unimelb.edu.au/accessibility/tutorials/zoom/zoom-meetings-and-closed-captions | . | Ai-Media Blog offers many informative posts including closed captioning how-to, tips for being Deaf-aware, what is Audism: https://www.ai-media.tv/ai-media-blog/ | Great example of commitment to accessibility at Griffith University: https://www.griffith.edu.au/accessibility/creating-accessible-learning-environments/auslan-interpreters-and-captioning-for-events | Another example of how to create accessible events from University College London: https://www.ucl.ac.uk/equality-diversity-inclusion/equality-areas/disability-equality/tips-checklist-making-events-accessible | . Back to top . ",
    "url": "http://localhost:4000/10_improving_communication_access.html#improving-communication-access-for-deaf-and-hard-of-hearing-people",
    "relUrl": "/10_improving_communication_access.html#improving-communication-access-for-deaf-and-hard-of-hearing-people"
  },"17": {
    "doc": "Improving Communication Access",
    "title": "Improving Communication Access",
    "content": ". | Improving communication access for deaf and hard of hearing people . | Captioning options to improve accessibility of your audio-visual content . | Some terms used | What type of access could be offered and when? | How to caption pre-recorded content . | Creating captions using YouTube | Options for live captioning of online event . | Captions by AI -Artificial Intelligence | Live human captioning during online meeting | . | . | . | Providing interpreters who can work between signed and spoken languages . | Sign language interpreters | Steps &amp; responsibilities involved in finding, booking &amp; working with interpreters | . | Services and Tools | Other Helpful Links | . | . ",
    "url": "http://localhost:4000/10_improving_communication_access.html",
    "relUrl": "/10_improving_communication_access.html"
  },"18": {
    "doc": "PARADISEC Internal Ingestion Model",
    "title": "PARADISEC Ingestion Workflow Model",
    "content": ". 🚧 This page is currently under construction🚧 . Last updated: 5 July 2021 . Content for this document was last updated 22 December 2020. Previous iterations of our Operations Manual (prior to implementation of the Nabu catalogue) are available from the downloads section of our website https://www.paradisec.org.au/. For questions or comments on this document please contact us at admin@paradisec.org.au, or write to us at: PARADISEC Sydney Conservatorium of Music, C41 University of Sydney, 2006 Ph: +61 2 9351 1279, Fax: +61 2 9351 1287 . Role terms used in this document Admin: Sydney Director (2020: Amanda Harris) Audio: Audio Preservation Officer (2020: Nick Fowler-Gilmore) PD: Project Director (2020: Nicholas Thieberger) SA: Systems Admin (2020: University of Sydney ICT) . Pre-ingestion (audio tapes) . Assess collection (Admin and PD) . Assess whether material is suitable for accession (PD in consultation with steering committee). Suitability should consider the following conditions, though materials not meeting these criteria are not necessarily excluded from the collection: . Rights Does the depositor assert ownership of the material? . | Are the rights in the material clearly specified? | Content criteria (assess against policy) . | is the material unique? | is the country and language of the material known, and in the core area (non-Australian)? | is there an alternative place for deposit of the recording? | is the content of the recording in a high-risk language? | is the format or recording medium at high-risk of obsolescence? | institutional affiliation – give preference to consortium members | ease of integration into our systems . | is data in a format we can handle (i.e. cassette, 1/4 inch reels)? | if not, direct prospective depositor to suitable alternative facility | . | consistency and adequacy of any metadata | . | . If collection assessed as suitable, create a collection record in Nabu Assess tape condition and prepare material for transportation accordingly . Transportation . If the recordings are in bad condition (e.g. mould, rare formats, tape visibly damaged) send to Sydney (contact Admin). Transport any mouldy items in separate ziplock bags and do not pack with non-mouldy items . If in reasonable condition transport to nearest ingestion point, personal transport is preferable; transport in hand luggage if flying, if necessary use registered courier . | Packing – make sure end fastened on reel tape, pack tightly, wrap in bubble wrap | Ensure against unnecessary shocks during transport | Transport with inventory of contents | . Receipt of materials at ingestion point (Admin) . | Check inventory against contents and contact depositor if any discrepancy | Enter date in ‘data received’ field of Nabu | Assess whether mould-affected and if so implement appropriate procedure (put in ziplock bags and store in cleaning room) | . Metadata . Where possible get depositors to enter own metadata in Nabu: . | User signs up to Nabu, creating a login | Admin or PD assigns edit access to user | . Assign Persistent Identifier (PI) – if depositor already has a consistent naming system, use it, or else use numerical symbols for ‘item ID’, e.g. 001 . Where depositor cannot enter own metadata, enter records manually or batch import records from a spreadsheet . | For batch import of new records: ensure all metadata is inserted into the PARADISEC basic metadata import spreadsheet located at http://www.paradisec.org.au/downloads.html{:target=”_blank”} (only those fields listed in the spreadsheet can be imported, and no changes should be made to fields or headings in the spreadsheet, metadata should only be added to existing fields) . | Open Nabu and click on the Dashboard tab | Click on ‘Upload metadata file’ button | Browse to location of file | Click on ‘Add Collection from Spreadsheet XLS file’ | . | For manual entry of new records: . | Create item records (Admin) by adding item IDs and descriptions into the Collection screen | Enter all metadata available into appropriate fields of catalogue, ensuring that all compulsory fields (marked with a red asterisk) have been filled | . | . Label all tapes and tape cases to show PI, ensuring that no written information is covered up . Sort all tapes in numerical order in filing cabinet, or in dirty room if mould-affected . When tapes returned, note date in ‘tracking’ field of Item, Archive Information and tick ‘Tapes returned to depositor’ checkbox . Photograph tape covers and casings to capture all handwritten metadata . | Image files should be named with the same PI as the audio files | Archival copies of images should be in tiff (.tif) format, jpeg (.jpg) copies can be archived as additional access copies | The whole image should be captured, but in some cases it might be desirable to zoom in to the text to make sure it is fully legible in an additional image | Even blank surfaces should be photographed to ensure that no metadata has been overlooked | Include a ruler in the captured image to indicate scale | See the Appendix at the end of this document on guidelines for image capture and also the Austehc image capture guidelines in the 2011 PARADISEC Operations Manual for more details | . Prepare tapes for ingestion (Audio) . | Assess tape condition – treat mouldy items according to the below procedure (wear a mask and latex gloves as protective gear) | Dehumidify in vacuum oven if necessary, with separate batches for mould-affected items | If necessary, advice regarding duration of treatment and temperature can be found at NFSA and also within the IASA TC-04 Guidelines | If mouldy remove any visible growths first with cotton bud or pad and solution of isopropyl and cetramide | If sticky shed is present no special prior treatment is needed | Clean and prepare for ingestion | . Reel-to-reel . | Repair or replace lead tape and damaged splices if necessary | Clean using slow spool and specialist equipment (cotton pads and isopropyl/cetramide solution); also clean flange (spool) separately | Perform a second slow spool to repack tape | . Cassette and DAT . | Replace splices if necessary (cassette) | Fast forward and rewind to minimise print-through (cassette) and to repack tape (cassette and DAT) | If mouldy, bag up separately, to avoid cross-contamination, shelve in PARADISEC’s Dirty Room and minimise time in Ingestion Room, replay on designated dirty cassette machine | . Information on devices and servicing . | Format | Device | Date last tested | . | Cassette | TASCAM 122 Mk II | July 2014 | . | Mouldy cassette | Yamaha KX-W32 | July 2014 | . | Reel-to-reel 15 ips | Studer A810 | July 2014 | . | Reel-to-reel 7 1/2 ips | Studer A810 | July 2014 | . | Reel-to-reel 3 3/4 ips | Studer A810 | July 2014 | . | Reel-to-reel 7/8 ips | No suitable in-house machine | as of October 2015 | . | Minidisk | Processed at Melbourne | n/a | . | *.wav files | Procesed at Melbourne, ANU or APAC | 2015 | . | DAT | Sony PCM 7040 | July 2014 | . | CD | CD inspector on Audiocube 3 | n/a | . Ingestion process . Wavelab ingestion processes - Sydney Lab (Audio) . | Avoid internet browsing and any activity over the network during digitisation (these activities can cause interference, which may result in digital clips and unwanted errors in the signal), avoid using or turn off mobile phones or other mobile devices, including close wi-fi transmitters, and as a precaution, close any programs other than WaveLab during recording of audio. | Reel-to-reel tapes go through Audio1 workstation (where StuderA810 is connected), cassette tapes go through either Audio1 or Audio2 workstations (both fitted with Tascam 122MKII’s cassette tape machines). Other sources, such as vinyl records, are to be connected separately as required and may, depending on how the device is connected, go through either Audio1 or Audio2 ingest stations. | Open the ‘record’ dialogue box (the button with the red circle at the bottom of the screen) and type in the name and path of the file that you will create. The destination folder will, on either audio machine, be ‘D:/WAV96 ingest’ (shortcut on desktop) followed by the name of the audio file ‘CollID-ItemID.wav’. Relevant subparts of an item are indicated ‘-A’, ‘-B’ for example, and are inserted after the PI and before the extension. | If digitization is being done from a copy tape (rather than an original), then ‘copy’ needs to be added into the third part of the filename (e.g. ‘AC1-001-A_copy’). This is so that we can avoid having to overwrite DOIs if a later file is produced from the original; the subsequent file can then be added, rather than replacing the ‘copy’ file, and it can be appropriately named (e.g. ‘AC1-001-A_original’). | If further work will be required on a file, such as splitting it into two separate channels, then the file should take a name that is distinct from the files that will ultimately be produced, to preclude any confusion. For instance, if the files to be archived will eventually be named AW1-001-A.wav and -B.wav and they are two sides of a single ingested recording that will require splitting, then name the file that comprises each of them as AW1-001_ The underscore as opposed to a dash will prevent the file from being erroneously archived. (Using Rif64 file format in Dobbin, we can now overcome our 2GB limit and so splitting of large files is not usually necessary). | It is a good idea to run the signal for a few seconds and adjust the level on the source selector so that it maxes out at about -100 dB on the record dialogue (the white stickers on the source selector are a rough approximation of good gain levels for the selected source). After a good level is established, return the tape to the beginning and commence recording, leaving at least 5 seconds of silence before the signal begins. | Adjust the azimuth - this is the angle at which the tape meets the head, and we want to adjust it so we can get the sharpest (closest to original position of record head) possible signal. You will need to have the cover off the tape deck. In the monitoring window, enable Phase scope in WaveLab - you will see a graph in the bottom-right, with clusters of moving points showing as the tape plays; ideally, these should line up along one of the axes. [Cassettes] Take the small flat screwdriver, and tweak the screw on the bottom-left of the cassette playback head slot (not the right screw), while the tape is playing. Use only very small movements – you don’t want to unscrew the screw and lose it in the machine. Listen carefully – you should hear the recording start to become sharper, as well as see the points start to line up more on the graph. Adjust the screw back after use. [R2R] Adjust the azimuth as it plays - use the allen key to turn the screw behind the heads. You should hear the recording get sharper, and see the moving points start to form a straight line in the graph in the monitoring window. | pay attention to the recording and note any analogue errors, such as pops, hisses, buzzing, microphone bumps. These should be noted in the ‘ingest notes’ in the catalogue. More generally, note the overall quality of the recording — whether it is at all muffled, distorted or good and clean. This information should also go into ‘ingest notes’. | analyse the file in Wavelab (shortcut: control-Y) (takes about 2 minutes for normal length file) — this generates temporary error markers wherever recording faults are apparent . | check any errors: if they are analogue errors, make a note of them in ‘ingest notes’; if they are digital errors, re-ingest – file size, waveform, length sample rate might need to be checked and adjusted in Wavelab. Where more serious corruption has occurred, check the most recent backup (there should be one somewhere). Keep regressing in stages until you find a version of the file’s history that is not corrupted. If no such file exists, contact the depositor to establish if the file had been corrupted prior to being received. | . | Enter additional metadata into Nabu . | Enter dates digitised | Enter name of operator in Operator field | If recorded tape ID mentions date created, tape ID, recordist, or any other info not already in database, fill in relevant fields (check with admin as necessary, if unsure, leave blank) | . | if necessary, normalise the file. This should not normally be necessary where premonitoring has taken place and the tapes are in good enough condition to yield a good quality sound level. | after ingestion finished, trim silence at beginning and end of file, leaving margin of 5 seconds’ silence | in the case of stereo reel-to-reel tapes that comprise two simultaneous mono recordings, split the 2 channels . | name the files appropriately (for the time being, leave the raw, unedited files (the ones with underscored names instead of dashed ones) in this folder until a later backup can be made) . | check that mandatory metadata fields (PI, title, date created, country, collector) are in Nabu catalogue, if not, add them. If you are unsure of what information to enter into the catalogue, liaise with Admin . | Before adding files to Nabu, all mac users must ensure they delete any hidden files (they start with a . e.g. ‘.DS_Store’) so they do not cause errors, and also delete them immediately from the ‘Processing Area\\forDobbin’ folder if they appear in there during the process of copying files across. To do this all Mac users must switch on viewing of invisible or hidden files. Instructions can be found here: http://www.macworld.co.uk/how-to/macsoftware/how-show-hidden-files-in-mac-os-x-finder-funter-3520878/ . | place files in parapd00470.srv.sydney.edu.au\\Processing Area\\forDobbin, this will trigger Nabu to create matching .imp and .id3 xml export files (see below section Dobbin Processes for BWF generation for details). Otherwise, if more work will be undertaken at a later time, files should be placed on the server in parapd00470.srv.sydney.edu.au\\Processing Area\\waitingArea. | . Dobbin processes for BWF generation (Audio) . | NABU monitors ‘forDobbin’ directory for .wav files, and when it finds one, it writes out the metadata for the corresponding item – if the item is marked ‘Ready for metadata export’ in the Item’s Admin panel. The exported metadata files are: . | parapd00470.srv.sydney.edu.au\\Processing Area\\xml[PID].imp.xml | parapd00470.srv.sydney.edu.au\\Processing Area\\id3[PID].id3.v2_3.xml | . | XMLcheck monitors ‘forDobbin’ directory, and if a .wav file exists, it then also checks to see whether both the corresponding .imp.xml and .idv2_xml files exist. If both xml files are in the right directories, it moves the .wav file into the directory ‘processed\\fromDobbin’. | Dobbin monitors ‘forDobbin’ for .wav files. When it finds a .wav file, it begins processing it. To do this it requires the .imp.xml file and the .idv2_xml files to be in the correct locations. Dobbin outputs a sealed BWF file with a .wav suffix and a derivative .mp3 file. Dobbin also produces a .qua file for each of these. These .qua files are generated only after the files have been successfully written to the output directory, which is ‘processed\\fromDobbin’. | BWFhashgenerator monitors the ‘processed\\fromDobbin’ directory for .wav files. If it finds one, along with a corresponding .mp3, .wav.qua and .mpqua, then it generates a hashsum for the wav and mp3, and writes them out to a file named [file]-checksum-PDSC_ADMIN.txt, which will contain the checksums for both wav and mp3 It then writes both .wav and .mp3, as well as the checksum .txt file, to ‘toNabu’, from which NABU harvests archive files. | this process commences once the wav file is in the folder ‘parapd00470.srv.sydney.edu.au\\Processing Area\\forDobbin’ and the necessary metadata has been entered into the catalogue (see above). Wrapping includes the necessary metadata and digitally seals the file to prevent it being altered . | a backup of the file is kept in ‘parapd00470.srv.sydney.edu.au\\Processing Area\\processed\\forDobbin’. This folder is used as a backup of the raw .wav files before they are processed in Dobbin and uploaded to the archive as bwfs and mp3s. Once we have received a report from Cron deploy@paradisec stating the file was SUCCESSFUL in its upload to our catalogue and the file appears in Nabu in its proper format, with relevant matching metadata. Then we can delete our original raw .wav backup copy. If this file generates an ERROR message, then we can refer back to our original .wav backup copy and reprocess. | A script searches ‘forDobbin’ for any newly added wav files and harvests the file name, size and the audio properties and places a reference to them in the catalogue entry for that item | . Ingestion of photographic slides . The process for ingesting slides and digital image capture is documented in Paradisec Operations Manual 2011, and the appended Austech manual http://www.paradisec.org.au/downloads.html. Contact PARADISEC staff for further details. Digital text . | formatted documents, e.g. in MS Word format, need to be saved as .rtf and .pdf, .docx files can also be archived. Check each file for character encodings. Use doxillion for mass file conversions. | if the file is of a specific type (e.g. a Toolbox file) then it needs to have sufficient documentation to make it readable (e.g. it may need .typ files accompany it). | put the files into the ‘toNabu’ folder where a script will pick them up to send to Nabu . | . University of Melbourne ingestion unit . This suite consists of a purpose-built computer, with a Digital Audio Denmark analogue to digital converter, a cassette player, minidisk player and reel-to-reel player. The computer has no internet connection (to prevent digital noise in the digitisation) so a hard disk is used to transport the files to another computer for transfer. | Enter planned work times in PARADISEC google calendar in advance | Enter details of tapes completed into the google spreadsheet | Turn on computer – bottom one | Log in | . Metadata (done on a different computer that has an internet connection) . | Log on to catalog.paradisec.org.au | Dashboard will show collections you are already working on, for view or edit | Can search by collection ID in ‘Collections’ tab | Enter all possible metadata, including what the source media are, who is the operator (i.e. you), and add audio notes (below) | . Setting up for recording . | Open WaveLab 8.5 (click yes to run) | Click record button to open recording dialogue box | Enter folder and filename (have a folder for your work and subfolders of collection within that) | File name format is XX1-001-A (collection, tape number, side A or B if needed) | Select 24-96 sampling rate in the dialogue box | Auto-stop after given duration – check if this is set (usually set to ~45 mins for one side of a cassette, but minidiscs and some tapes longer) | . To record – cassette tapes . | Can lock the tape by pushing in the plastic lugs | Check condition of tape, if there is anything strange about the way the tape runs through the mechanism, or if there is evidence of mould on the edge of the spool, or if bits of the media are falling off (‘shedding’) then refer it to PD Nick Thieberger. | Settings are Jack, SP/DIF, Analog In, 96kHz 24bit, Int sync. | Make sure the leads to the Studer (reel-to-reel) are unplugged from the back of the Digital Audio Denmark unit. | Have output set to around 7 to start | Clean heads and capstans of playback machine with isopropyl alcohol and cotton tips | Fast forward once, right through both sides of recording, but be careful towards end of tape – tape can come loose with sudden stop. Can use the separate tape deck for this while digitising other tapes. | Play a bit to check levels. Can adjust output up or down as needed. Levels can be monitored on converter and in WaveLab. Around -12dB is good – not into the red. | If monitoring is not showing up in WaveLab, go to Options &gt; Preferences &gt; Audio device. This should be set to MME-WDM SPDIF/ADAT (1+2) (RME Babyface) for both playback device AND recording device. | Adjust the azimuth - this is the angle at which the tape meets the head, and we want to adjust it so we can get the sharpest possible recording. You will need to have the cover off the tape deck. In the monitoring window in WaveLab, you will see a graph in the bottomright, with clusters of moving points showing as the tape plays. Ideally, these should line up along one of the axes. Take the small flat screwdriver, and tweak the screw on the bottomleft of the cassette slot (not the right screw), while the tape is playing. Use only very small movements – you don’t want to unscrew the screw and lose it in the machine. Listen carefully – you should hear the recording start to become sharper, as well as see the points start to line up more on the graph. Adjust the screw back after use. | Hit record button in WaveLab. If it flashed red with ‘waiting’, hit again in order to record. Wait ~5 secs then hit ‘play’ on tape player. | . While playing Take audio notes: . | document state of original the recording | Whether mono or stereo | Which channel (left or right) | Any clipping in original | . When file finished . | Stop tape first then stop recording ~ 5 secs after (good to leave a bit of space at start and end) | Cut out any silence in file – click and drag to select (both channels), then hit delete (or right-click, ‘select from cursor to end of file’) | File &gt; Save | Flip cassettes to do other side. Note that tape player sometimes automatically reverses direction, make sure it is facing &gt; if you have turned tape yourself. | When tape is done, make sure to insert digitisation slip with date, name, item number | Remember to adjust the azimuth back to original position so the screw doesn’t come out when adjusting it for the next tape. | . To record – minidiscs . | Need to connect to fibre optic cable to the audio interface. It’s the one labelled ‘MD Out’. Take out the middle of the three cables on the interface and plug the minidisc cable in there. | Settings are Jack, Optical, Digital In, 96kHz 24bit, Int sync. | In WaveLab sampling rate option is 24-96 | Check the audio device preferences to make sure correct device is selected for both playback and recording (as per tapes). | May need to close and re-open the recording dialogue after changing settings to refresh | Hit record, then after ~ 5 secs hit play on MD player. Volume can’t be adjusted so digitise as is but keep audio notes. | . To record – DAT tapes . | [Unlikely that we will have to deal with DAT anymore] | . To record – reel-to-reel . | Set machine to ¼ inch, rest of the settings are same as for cassettes (96kHz 24bit) . | Switch on reel-to-reel machine - this is the black switch at the back of the lower part of the machine. Clean the heads before loading a reel. | Put the reel on the left spindle. You need to line up the two metal parts of the spindle to slide it on. Thread the leader tape across the heads, with the tape coming off the reel counter-clockwise and being threaded under the first guide wheel, over the next, then past the heads. If the reel has no leader tape, USE GLOVES to handle the tape and add some new leader tape using the splicing tape and block. Thread it onto an empty take-up reel on the right and wind on a little bit. Lock the supply reel and take-up reel in place by lifting the top part of the metal spindle up and turning it. | Fast forward once through the tape onto supply reel and swap the reels over and re-spool. Press play to listen to the audio. Speed should be set to match that of the reel if possible - lowest setting on machine is 3 ¾, so if tape has been recorded at a lower speed like 1 ⅞, record at 3 ¾ and fix in post-processing. | Adjust the azimuth as it plays - use the Allen key to turn the top right hand side screw on the play head. You should hear the recording get sharper, and see the moving points start to form a straight line in the graph in the monitoring window. | Adjust the volume - on the top of the machine, there are two pairs of knobs labelled ‘record level’ and ‘rep/sync level’. The tape may have a mono recording on each side, in which case you will see information being captured in each channel, but these tracks will be from separate recording sessions. If this is the case, it is the RIGHT CHANNEL you want to look at in the monitoring window. To adjust the levels for this, you want to adjust the rightmost of the first pair of knobs, or the first ‘rep/sync level’. As for cassettes, around 7 should be ok, but audio levels may vary quite a bit. If the tape is a stereo recording - i.e. audio was recording to both channels simultaneously - you will need to check that the levels are ok in both the left and right channel. | Once you have finished one side, you need to check if there is a Side B. If the tape has two mono tracks, you will have been able to see this while recording the first side, but the audio in the left channel will have been recorded in reverse and needs to be discarded and done separately. Take off the empty reel, and remove now-full take-up reel. Flip it over and load onto the left spindle, and then put your empty original reel on the right, and follow the same process. | Once you have recorded each mono side like this, save just the right channel from each track by going to File &gt; Save Special (Wave) &gt;: Save Right Channel As. This will save just the right channel as a mono file. | Save one as Side A and one as Side B * If the reel has a stereo recording on each side, there is no need to do this - just save each stereo file as Side A and B. | . Restore from archive proces (SA) . Restoring a file on Azoulay, which was modified or created in the last several days: . Note: If it is one of your files you can restore it, otherwise this action must be performed by the Super User (either Abed Kassis, or Tom Honeyman). You must be able to use a unix shell to do this. | Connect to Azoulay by ssh (ssh username@azoulay.arts.usyd.edu.au) | navigate to the directory to which you want to recover or wind back a file (cd /r0/… etc) | run ‘recover -s nsrhost’ | you should get a ‘recover&gt;‘ prompt. | ‘help’ will list available commands. ‘ls’ will list files that you can recover. | . note: files older than a month will not be shown. You may need to get an older tape loaded. Abed Kassis (or the ArtsIT server administrator) should handle this process by contacting ICT and getting them to load the correct tape. If you are recovering a file from the backups of ‘Send to Archive’ then the tape number listed in the catalogue is necessary. Note however, that it will probably be easier to recover the file from Store/APAC (see 2 below). IMPORTANT: you must monitor the recovery process as it will prompt you if you need to overwrite a file. Leaving your terminal without responding to the prompt will halt the tape robot, and may result in the automatic backups not working. Check PARADISEC repository reports (Admin/PD) . | check PARADISEC archiving report emailed weekly to all project members from deploy@paradisec.intersect.org.au | identify any anomalies and rectify, reprocessing relevant files as necessary. | . Access to Archived files in Paradisec repository individual collections list the items available as part of that collection. A label appears next to each item indicating whether access is open or closed. Users can click through to the individual files which can be streamed or downloaded directly from the catalogue. If an item has restricted conditions, the depositor may need to be contacted to request permission. Appendix: Notes on image capture equipment . | Canon Powershot G6 | Powerbook G4 | Camera tripod | Tungsten light bulbs | . Rotating the photographs If the ‘Rotation’ button is greyed out and not working in the Remote Shooting and Image Browser windows, then the camera might have the ‘Auto Rotate’ function on. This function automatically rotates the image according to which way the camera is being held (ie. Portrait or landscape), this is useful if the camera is vertical, but not useful if it is being held horizontally. To turn off the Auto Rotate function on the camera: . | On the camera, press the menu button | In the menu, use the arrow keys to scroll down to Auto Rotate | Press the left/right arrows to change it to ‘off’ | If the Auto Rotate function is off, you can rotate images in the remote capture window before you take the photograph and it will also change the orientation of the view finder. It is also possible to rotate the photograph afterwards in the Image Browser window by selecting the photograph and selecting ‘rotate’ in the ‘edit’ menu. | . Folders when starting the Remote Shooting window, you need to choose the folder that the photographs go into, the contents of which are displayed in the image browser. Put the photographs into a temporary folder (named eg. InProgess) first, and then, in ‘Finder’, to move the photographs to their proper folder afterwards. There are a few reasons for this: . | it is quicker to move images in ‘Finder’ after they have been taken than to change what folder they initially go in when the photo is taken. | the image browser slows down if it has too many (more than about 100) images to display, so if you are dealing with a large amount of photographs, you can transfer them to their proper folder progressively. | if you accidentally double click ‘send to trash’ it will not only delete all the photographs in the displayed in the Image Browser, but any other sub-folders that were also in the folder the photographs were saved in. It is all recoverable from the Trash, but is it still better to have a folder that has all its contents on display. | . Shooting Settings in the Remote Capture Window . | Photo Effect - changing the Photo Effect from ‘Effect Off’ to ‘Vivid’ makes light pencil and faded ink stand out better. | Focusing Point - the ‘Manual Selection – Center’ function means the process of taking the photograph and uploading it to the computer is slightly quicker because the camera does not refocus for each picture, because it automatically focuses on the centre of the image. However, if there is nothing in the centre of the page (for example the text is only at the top of the page, or in a column down the side of the page) or the writing is very pale, the image will be out of focus and it is better to change the Focusing Point to ‘Automatic Selection’. Generally, leaving it on ‘General Selection’ lessens the chance of a fuzzy picture because the camera re-focuses for each photograph. | Macro - if the ‘Automatic Selection’ focusing point is on and the image is still fuzzy, then change the Macro to ‘On’. | Lighting - having the lighting rig further away from the page makes the light more even. A higher lighting rig will also make it less likely to appear in large images where the camera has zoomed out, so it will not have to be moved very often. If the paper is shiny or there is pencil which reflects the light, putting paper light shades on the light bulbs or turning them off altogether (if there is adequate lighting from the room light or a window) reduces the reflection. | . General advice . | You can also release the shutter button by pressing the spacebar. | You can change the name of an individual in the Image Browser window by double clicking on it. | For images with little contrast (eg. Light pencil, faded ink), turning off the Tungsten light bulbs and, if there is daylight from a window, the room lights, as well as changing the Photo Effect in the Shooting Settings to ‘Vivid’ is a good way to get a clearer image. | If taking a lot of photographs of papers of a uniform size, drawing pencil dots on the backing cardboard to line up the paper speeds up the process. Folded-over post-it notes are a good way to stick down curling paper. | If you want to make a very small adjustment to the zoom, it is easier to adjust the height of the camera tripod than adjusting the zoom on the computer. | A suggestion for making copying books easier: if it were possible to make the automatic page numbering ‘odd’ or ‘even’, then every second page could be copied. This would be useful when photographing books because you could photograph all the left-hand pages and then all the right-hand pages, and you would only have to turn the page while keeping the book in place, rather than having to move it after taking each photograph. | . Back to top . ",
    "url": "http://localhost:4000/11_PDSC_ingestion_workflow.html#paradisec-ingestion-workflow-model",
    "relUrl": "/11_PDSC_ingestion_workflow.html#paradisec-ingestion-workflow-model"
  },"19": {
    "doc": "PARADISEC Internal Ingestion Model",
    "title": "PARADISEC Internal Ingestion Model",
    "content": ". | PARADISEC Ingestion Workflow Model . | Pre-ingestion (audio tapes) . | Assess collection (Admin and PD) | Transportation | Receipt of materials at ingestion point (Admin) | Metadata | Photograph tape covers and casings to capture all handwritten metadata | Prepare tapes for ingestion (Audio) | . | Ingestion process | Wavelab ingestion processes - Sydney Lab (Audio) . | Dobbin processes for BWF generation (Audio) | Ingestion of photographic slides | Digital text | . | University of Melbourne ingestion unit | Restore from archive proces (SA) | Appendix: Notes on image capture equipment | . | . ",
    "url": "http://localhost:4000/11_PDSC_ingestion_workflow.html",
    "relUrl": "/11_PDSC_ingestion_workflow.html"
  },"20": {
    "doc": "Overview",
    "title": "Overview of technical guides and workflows",
    "content": ". Last updated: 5 July 2021 . These technical workflows and archiving guides are designed to help people with different goals and different skill levels. If there is a topic you want to know about, but the information is not contained on these pages, feel free to reach out to us at PARADISEC and we will do our best to help. If you are just starting out and would like to know how to begin the process of archiving with PARADISEC these guides can help you get your materials in order. Getting started with PARADISEC . | How to become a PARADISEC user | How to start a collection | Archiving materials that come from analogue sources vs archiving born-digital materials | File-naming for PARADISEC | File formats we accept | . Metadata &amp; Data management . | Metadata entry with PARADISEC-formatted spreadsheets | Metadata entry with LaMeta | File naming requirements for PARADISEC | . The following guides offer suggestions for when you are creating content for archiving. This includes suggested camera/audio recorder settings when you are recording in the field, or instructions for those who are looking to digitise text material such as field notebooks. Suggested specifications for digital capture . | Camera settings (frame rate, file formats) | Audio settings (sample and bit rates) | Microphones | . Digitising manuscripts &amp; Field Notebooks . | Photo stands/tripods and lighting | Remote capture using computer and camera | Post-production processing of images | . If you are interested in audio-visual processing these guides can help. Audio digitising of analogue tapes . | Digitise audio cassette tapes and reel-to-reel tapes for archiving | . Audio procesing of born-digital files . | Resampling audio to meet PARADISEC archiving standards | Creating stereo track from mono track | . Video processing of MP4 (H.264) . | Create well-formed .MP4s for archival access copies or fit-for-purpose copies | Extract audio from video | Handle video with problematic properties in your attempts to make .MP4s | . Video processing of archival MXF . | Create lossless JPEG2000 video files for archiving with PARADISEC (archival copy) | Handle video with problematic properties for lossless MXF format | . CoEDL has released a set of guidelines for improving communication access for deaf and hard of hearing people. This page offers a simple but effect workflow for integrating captioning and/or sign laguage interpreting. Improving communication access for deaf &amp; hard of hearing people . | General tips for improving communication access | Ideas for captioning video presentations, both during and after an event | Tips on organising &amp; working with a sign language interpreter | . Back to top . ",
    "url": "http://localhost:4000/#overview-of-technical-guides-and-workflows",
    "relUrl": "/#overview-of-technical-guides-and-workflows"
  },"21": {
    "doc": "Overview",
    "title": "Overview",
    "content": ". | Overview of technical guides and workflows . | Getting started with PARADISEC | Metadata &amp; Data management | Suggested specifications for digital capture | Digitising manuscripts &amp; Field Notebooks | Audio digitising of analogue tapes | Audio procesing of born-digital files | Video processing of MP4 (H.264) | Video processing of archival MXF | Improving communication access for deaf &amp; hard of hearing people | . | . ",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  }
}
